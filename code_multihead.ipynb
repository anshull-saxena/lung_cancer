{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lung Histopathology Classification: ACA / N / SCC\n",
    "## Multi-CNN + Channel Attention + GA + KNN/SVM/RF + Fusion\n",
    "\n",
    "This notebook implements a comprehensive lung histopathology classification system that combines:\n",
    "- Multiple CNN backbones (DenseNet121, ResNet50, VGG16)\n",
    "- Channel attention mechanism (SE blocks)\n",
    "- Genetic Algorithm for feature selection\n",
    "- Ensemble of classical ML classifiers (KNN, SVM, Random Forest)\n",
    "- Majority voting fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.26.4 (from -r requirements.txt (line 1))\n",
      "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting pandas (from -r requirements.txt (line 2))\n",
      "  Downloading pandas-2.3.3-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\n",
      "Collecting scipy (from -r requirements.txt (line 3))\n",
      "  Downloading scipy-1.16.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (62 kB)\n",
      "Collecting tensorflow==2.16.1 (from -r requirements.txt (line 4))\n",
      "  Downloading tensorflow-2.16.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n",
      "Collecting scikit-learn (from -r requirements.txt (line 5))\n",
      "  Downloading scikit_learn-1.7.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
      "Collecting deap (from -r requirements.txt (line 6))\n",
      "  Downloading deap-1.4.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting Pillow (from -r requirements.txt (line 7))\n",
      "  Downloading pillow-12.0.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.8 kB)\n",
      "Collecting jupyter (from -r requirements.txt (line 8))\n",
      "  Using cached jupyter-1.1.1-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: ipykernel in /teamspace/studios/this_studio/.conda/lib/python3.11/site-packages (from -r requirements.txt (line 9)) (7.1.0)\n",
      "Collecting kagglehub (from -r requirements.txt (line 10))\n",
      "  Using cached kagglehub-0.3.13-py3-none-any.whl.metadata (38 kB)\n",
      "Collecting tqdm (from -r requirements.txt (line 11))\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting matplotlib (from -r requirements.txt (line 12))\n",
      "  Downloading matplotlib-3.10.7-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
      "Collecting seaborn (from -r requirements.txt (line 13))\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: psutil in /teamspace/studios/this_studio/.conda/lib/python3.11/site-packages (from -r requirements.txt (line 14)) (7.0.0)\n",
      "Requirement already satisfied: setuptools in /teamspace/studios/this_studio/.conda/lib/python3.11/site-packages (from -r requirements.txt (line 15)) (80.9.0)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow==2.16.1->-r requirements.txt (line 4))\n",
      "  Using cached absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow==2.16.1->-r requirements.txt (line 4))\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=23.5.26 (from tensorflow==2.16.1->-r requirements.txt (line 4))\n",
      "  Using cached flatbuffers-25.9.23-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow==2.16.1->-r requirements.txt (line 4))\n",
      "  Using cached gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow==2.16.1->-r requirements.txt (line 4))\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting h5py>=3.10.0 (from tensorflow==2.16.1->-r requirements.txt (line 4))\n",
      "  Downloading h5py-3.15.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting libclang>=13.0.0 (from tensorflow==2.16.1->-r requirements.txt (line 4))\n",
      "  Using cached libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting ml-dtypes~=0.3.1 (from tensorflow==2.16.1->-r requirements.txt (line 4))\n",
      "  Downloading ml_dtypes-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow==2.16.1->-r requirements.txt (line 4))\n",
      "  Using cached opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in /teamspace/studios/this_studio/.conda/lib/python3.11/site-packages (from tensorflow==2.16.1->-r requirements.txt (line 4)) (25.0)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow==2.16.1->-r requirements.txt (line 4))\n",
      "  Using cached protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "Collecting requests<3,>=2.21.0 (from tensorflow==2.16.1->-r requirements.txt (line 4))\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in /teamspace/studios/this_studio/.conda/lib/python3.11/site-packages (from tensorflow==2.16.1->-r requirements.txt (line 4)) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow==2.16.1->-r requirements.txt (line 4))\n",
      "  Using cached termcolor-3.2.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /teamspace/studios/this_studio/.conda/lib/python3.11/site-packages (from tensorflow==2.16.1->-r requirements.txt (line 4)) (4.15.0)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow==2.16.1->-r requirements.txt (line 4))\n",
      "  Downloading wrapt-2.0.0-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (8.8 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow==2.16.1->-r requirements.txt (line 4))\n",
      "  Downloading grpcio-1.76.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.7 kB)\n",
      "Collecting tensorboard<2.17,>=2.16 (from tensorflow==2.16.1->-r requirements.txt (line 4))\n",
      "  Using cached tensorboard-2.16.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.0.0 (from tensorflow==2.16.1->-r requirements.txt (line 4))\n",
      "  Using cached keras-3.12.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow==2.16.1->-r requirements.txt (line 4))\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests<3,>=2.21.0->tensorflow==2.16.1->-r requirements.txt (line 4))\n",
      "  Downloading charset_normalizer-3.4.4-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (37 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3,>=2.21.0->tensorflow==2.16.1->-r requirements.txt (line 4))\n",
      "  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2.21.0->tensorflow==2.16.1->-r requirements.txt (line 4))\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3,>=2.21.0->tensorflow==2.16.1->-r requirements.txt (line 4))\n",
      "  Using cached certifi-2025.10.5-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.17,>=2.16->tensorflow==2.16.1->-r requirements.txt (line 4))\n",
      "  Using cached markdown-3.9-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.17,>=2.16->tensorflow==2.16.1->-r requirements.txt (line 4))\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.17,>=2.16->tensorflow==2.16.1->-r requirements.txt (line 4))\n",
      "  Using cached werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /teamspace/studios/this_studio/.conda/lib/python3.11/site-packages (from pandas->-r requirements.txt (line 2)) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas->-r requirements.txt (line 2))\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->-r requirements.txt (line 2))\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn->-r requirements.txt (line 5))\n",
      "  Downloading joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->-r requirements.txt (line 5))\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting notebook (from jupyter->-r requirements.txt (line 8))\n",
      "  Using cached notebook-7.4.7-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting jupyter-console (from jupyter->-r requirements.txt (line 8))\n",
      "  Using cached jupyter_console-6.6.3-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting nbconvert (from jupyter->-r requirements.txt (line 8))\n",
      "  Downloading nbconvert-7.16.6-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting ipywidgets (from jupyter->-r requirements.txt (line 8))\n",
      "  Downloading ipywidgets-8.1.7-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting jupyterlab (from jupyter->-r requirements.txt (line 8))\n",
      "  Using cached jupyterlab-4.4.10-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: comm>=0.1.1 in /teamspace/studios/this_studio/.conda/lib/python3.11/site-packages (from ipykernel->-r requirements.txt (line 9)) (0.2.3)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /teamspace/studios/this_studio/.conda/lib/python3.11/site-packages (from ipykernel->-r requirements.txt (line 9)) (1.8.16)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /teamspace/studios/this_studio/.conda/lib/python3.11/site-packages (from ipykernel->-r requirements.txt (line 9)) (9.6.0)\n",
      "Requirement already satisfied: jupyter-client>=8.0.0 in /teamspace/studios/this_studio/.conda/lib/python3.11/site-packages (from ipykernel->-r requirements.txt (line 9)) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /teamspace/studios/this_studio/.conda/lib/python3.11/site-packages (from ipykernel->-r requirements.txt (line 9)) (5.9.1)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /teamspace/studios/this_studio/.conda/lib/python3.11/site-packages (from ipykernel->-r requirements.txt (line 9)) (0.2.1)\n",
      "Requirement already satisfied: nest-asyncio>=1.4 in /teamspace/studios/this_studio/.conda/lib/python3.11/site-packages (from ipykernel->-r requirements.txt (line 9)) (1.6.0)\n",
      "Requirement already satisfied: pyzmq>=25 in /teamspace/studios/this_studio/.conda/lib/python3.11/site-packages (from ipykernel->-r requirements.txt (line 9)) (27.1.0)\n",
      "Requirement already satisfied: tornado>=6.2 in /teamspace/studios/this_studio/.conda/lib/python3.11/site-packages (from ipykernel->-r requirements.txt (line 9)) (6.5.1)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in /teamspace/studios/this_studio/.conda/lib/python3.11/site-packages (from ipykernel->-r requirements.txt (line 9)) (5.14.3)\n",
      "Collecting pyyaml (from kagglehub->-r requirements.txt (line 10))\n",
      "  Downloading pyyaml-6.0.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.4 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib->-r requirements.txt (line 12))\n",
      "  Downloading contourpy-1.3.3-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib->-r requirements.txt (line 12))\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib->-r requirements.txt (line 12))\n",
      "  Downloading fonttools-4.60.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (112 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib->-r requirements.txt (line 12))\n",
      "  Downloading kiwisolver-1.4.9-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.3 kB)\n",
      "Collecting pyparsing>=3 (from matplotlib->-r requirements.txt (line 12))\n",
      "  Downloading pyparsing-3.2.5-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /teamspace/studios/this_studio/.conda/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow==2.16.1->-r requirements.txt (line 4)) (0.45.1)\n",
      "Requirement already satisfied: decorator in /teamspace/studios/this_studio/.conda/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 9)) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in /teamspace/studios/this_studio/.conda/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 9)) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /teamspace/studios/this_studio/.conda/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 9)) (0.19.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /teamspace/studios/this_studio/.conda/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 9)) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /teamspace/studios/this_studio/.conda/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 9)) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /teamspace/studios/this_studio/.conda/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 9)) (2.19.2)\n",
      "Requirement already satisfied: stack_data in /teamspace/studios/this_studio/.conda/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 9)) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in /teamspace/studios/this_studio/.conda/lib/python3.11/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel->-r requirements.txt (line 9)) (0.2.14)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /teamspace/studios/this_studio/.conda/lib/python3.11/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->-r requirements.txt (line 9)) (0.8.5)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /teamspace/studios/this_studio/.conda/lib/python3.11/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->-r requirements.txt (line 9)) (4.5.0)\n",
      "Collecting rich (from keras>=3.0.0->tensorflow==2.16.1->-r requirements.txt (line 4))\n",
      "  Using cached rich-14.2.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.0.0->tensorflow==2.16.1->-r requirements.txt (line 4))\n",
      "  Using cached namex-0.1.0-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting optree (from keras>=3.0.0->tensorflow==2.16.1->-r requirements.txt (line 4))\n",
      "  Downloading optree-0.17.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (33 kB)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /teamspace/studios/this_studio/.conda/lib/python3.11/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel->-r requirements.txt (line 9)) (0.7.0)\n",
      "Collecting MarkupSafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow==2.16.1->-r requirements.txt (line 4))\n",
      "  Downloading markupsafe-3.0.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.7 kB)\n",
      "Collecting widgetsnbextension~=4.0.14 (from ipywidgets->jupyter->-r requirements.txt (line 8))\n",
      "  Downloading widgetsnbextension-4.0.14-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab_widgets~=3.0.15 (from ipywidgets->jupyter->-r requirements.txt (line 8))\n",
      "  Downloading jupyterlab_widgets-3.0.15-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting async-lru>=1.0.0 (from jupyterlab->jupyter->-r requirements.txt (line 8))\n",
      "  Downloading async_lru-2.0.5-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting httpx<1,>=0.25.0 (from jupyterlab->jupyter->-r requirements.txt (line 8))\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jinja2>=3.0.3 (from jupyterlab->jupyter->-r requirements.txt (line 8))\n",
      "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting jupyter-lsp>=2.0.0 (from jupyterlab->jupyter->-r requirements.txt (line 8))\n",
      "  Downloading jupyter_lsp-2.3.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting jupyter-server<3,>=2.4.0 (from jupyterlab->jupyter->-r requirements.txt (line 8))\n",
      "  Downloading jupyter_server-2.17.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting jupyterlab-server<3,>=2.27.1 (from jupyterlab->jupyter->-r requirements.txt (line 8))\n",
      "  Downloading jupyterlab_server-2.28.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting notebook-shim>=0.2 (from jupyterlab->jupyter->-r requirements.txt (line 8))\n",
      "  Downloading notebook_shim-0.2.4-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting anyio (from httpx<1,>=0.25.0->jupyterlab->jupyter->-r requirements.txt (line 8))\n",
      "  Downloading anyio-4.11.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.25.0->jupyterlab->jupyter->-r requirements.txt (line 8))\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.25.0->jupyterlab->jupyter->-r requirements.txt (line 8))\n",
      "  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting argon2-cffi>=21.1 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 8))\n",
      "  Downloading argon2_cffi-25.1.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting jupyter-events>=0.11.0 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 8))\n",
      "  Downloading jupyter_events-0.12.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting jupyter-server-terminals>=0.4.4 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 8))\n",
      "  Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting nbformat>=5.3.0 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 8))\n",
      "  Downloading nbformat-5.10.4-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting overrides>=5.0 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 8))\n",
      "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting prometheus-client>=0.9 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 8))\n",
      "  Downloading prometheus_client-0.23.1-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting send2trash>=1.8.2 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 8))\n",
      "  Downloading Send2Trash-1.8.3-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting terminado>=0.8.3 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 8))\n",
      "  Downloading terminado-0.18.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting websocket-client>=1.7 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 8))\n",
      "  Downloading websocket_client-1.9.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting babel>=2.10 (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->-r requirements.txt (line 8))\n",
      "  Downloading babel-2.17.0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting json5>=0.9.0 (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->-r requirements.txt (line 8))\n",
      "  Downloading json5-0.12.1-py3-none-any.whl.metadata (36 kB)\n",
      "Collecting jsonschema>=4.18.0 (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->-r requirements.txt (line 8))\n",
      "  Downloading jsonschema-4.25.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting sniffio>=1.1 (from anyio->httpx<1,>=0.25.0->jupyterlab->jupyter->-r requirements.txt (line 8))\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting argon2-cffi-bindings (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 8))\n",
      "  Downloading argon2_cffi_bindings-25.1.0-cp39-abi3-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl.metadata (7.4 kB)\n",
      "Collecting attrs>=22.2.0 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->-r requirements.txt (line 8))\n",
      "  Downloading attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->-r requirements.txt (line 8))\n",
      "  Downloading jsonschema_specifications-2025.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->-r requirements.txt (line 8))\n",
      "  Downloading referencing-0.37.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->-r requirements.txt (line 8))\n",
      "  Downloading rpds_py-0.28.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting python-json-logger>=2.0.4 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 8))\n",
      "  Downloading python_json_logger-4.0.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting rfc3339-validator (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 8))\n",
      "  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting rfc3986-validator>=0.1.1 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 8))\n",
      "  Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting fqdn (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 8))\n",
      "  Downloading fqdn-1.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting isoduration (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 8))\n",
      "  Downloading isoduration-20.11.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting jsonpointer>1.13 (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 8))\n",
      "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting rfc3987-syntax>=1.1.0 (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 8))\n",
      "  Downloading rfc3987_syntax-1.1.0-py3-none-any.whl.metadata (7.7 kB)\n",
      "Collecting uri-template (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 8))\n",
      "  Downloading uri_template-1.3.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "Collecting webcolors>=24.6.0 (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 8))\n",
      "  Downloading webcolors-24.11.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting beautifulsoup4 (from nbconvert->jupyter->-r requirements.txt (line 8))\n",
      "  Downloading beautifulsoup4-4.14.2-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting bleach!=5.0.0 (from bleach[css]!=5.0.0->nbconvert->jupyter->-r requirements.txt (line 8))\n",
      "  Downloading bleach-6.3.0-py3-none-any.whl.metadata (31 kB)\n",
      "Collecting defusedxml (from nbconvert->jupyter->-r requirements.txt (line 8))\n",
      "  Downloading defusedxml-0.7.1-py2.py3-none-any.whl.metadata (32 kB)\n",
      "Collecting jupyterlab-pygments (from nbconvert->jupyter->-r requirements.txt (line 8))\n",
      "  Downloading jupyterlab_pygments-0.3.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting mistune<4,>=2.0.3 (from nbconvert->jupyter->-r requirements.txt (line 8))\n",
      "  Downloading mistune-3.1.4-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting nbclient>=0.5.0 (from nbconvert->jupyter->-r requirements.txt (line 8))\n",
      "  Downloading nbclient-0.10.2-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting pandocfilters>=1.4.1 (from nbconvert->jupyter->-r requirements.txt (line 8))\n",
      "  Downloading pandocfilters-1.5.1-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting webencodings (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->jupyter->-r requirements.txt (line 8))\n",
      "  Downloading webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting tinycss2<1.5,>=1.1.0 (from bleach[css]!=5.0.0->nbconvert->jupyter->-r requirements.txt (line 8))\n",
      "  Downloading tinycss2-1.4.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting fastjsonschema>=2.15 (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 8))\n",
      "  Downloading fastjsonschema-2.21.2-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting lark>=1.2.2 (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 8))\n",
      "  Downloading lark-1.3.1-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting cffi>=1.0.1 (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 8))\n",
      "  Downloading cffi-2.0.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.6 kB)\n",
      "Collecting pycparser (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 8))\n",
      "  Downloading pycparser-2.23-py3-none-any.whl.metadata (993 bytes)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4->nbconvert->jupyter->-r requirements.txt (line 8))\n",
      "  Downloading soupsieve-2.8-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting arrow>=0.15.0 (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 8))\n",
      "  Downloading arrow-1.4.0-py3-none-any.whl.metadata (7.7 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.0.0->tensorflow==2.16.1->-r requirements.txt (line 4))\n",
      "  Using cached markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow==2.16.1->-r requirements.txt (line 4))\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: executing>=1.2.0 in /teamspace/studios/this_studio/.conda/lib/python3.11/site-packages (from stack_data->ipython>=7.23.1->ipykernel->-r requirements.txt (line 9)) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /teamspace/studios/this_studio/.conda/lib/python3.11/site-packages (from stack_data->ipython>=7.23.1->ipykernel->-r requirements.txt (line 9)) (3.0.0)\n",
      "Requirement already satisfied: pure_eval in /teamspace/studios/this_studio/.conda/lib/python3.11/site-packages (from stack_data->ipython>=7.23.1->ipykernel->-r requirements.txt (line 9)) (0.2.3)\n",
      "Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m155.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow-2.16.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (589.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m589.8/589.8 MB\u001b[0m \u001b[31m90.9 MB/s\u001b[0m  \u001b[33m0:00:04\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading grpcio-1.76.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m182.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m169.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.4-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (151 kB)\n",
      "Using cached idna-3.11-py3-none-any.whl (71 kB)\n",
      "Using cached tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Downloading pandas-2.3.3-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m156.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.16.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (35.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.9/35.9 MB\u001b[0m \u001b[31m197.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.7.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m185.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading deap-1.4.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (135 kB)\n",
      "Downloading pillow-12.0.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (7.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m181.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached jupyter-1.1.1-py2.py3-none-any.whl (2.7 kB)\n",
      "Using cached kagglehub-0.3.13-py3-none-any.whl (68 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading matplotlib-3.10.7-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m196.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Using cached absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Using cached certifi-2025.10.5-py3-none-any.whl (163 kB)\n",
      "Downloading contourpy-1.3.3-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (355 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached flatbuffers-25.9.23-py2.py3-none-any.whl (30 kB)\n",
      "Downloading fonttools-4.60.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (5.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m190.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading h5py-3.15.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (4.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m172.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Using cached keras-3.12.0-py3-none-any.whl (1.5 MB)\n",
      "Downloading kiwisolver-1.4.9-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m124.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "Using cached markdown-3.9-py3-none-any.whl (107 kB)\n",
      "Using cached opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading pyparsing-3.2.5-py3-none-any.whl (113 kB)\n",
      "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m158.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached termcolor-3.2.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Using cached werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Downloading markupsafe-3.0.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (22 kB)\n",
      "Downloading wrapt-2.0.0-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (114 kB)\n",
      "Downloading ipywidgets-8.1.7-py3-none-any.whl (139 kB)\n",
      "Downloading jupyterlab_widgets-3.0.15-py3-none-any.whl (216 kB)\n",
      "Downloading widgetsnbextension-4.0.14-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m180.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached jupyter_console-6.6.3-py3-none-any.whl (24 kB)\n",
      "Using cached jupyterlab-4.4.10-py3-none-any.whl (12.3 MB)\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading jupyter_server-2.17.0-py3-none-any.whl (388 kB)\n",
      "Downloading jupyterlab_server-2.28.0-py3-none-any.whl (59 kB)\n",
      "Downloading anyio-4.11.0-py3-none-any.whl (109 kB)\n",
      "Downloading argon2_cffi-25.1.0-py3-none-any.whl (14 kB)\n",
      "Downloading async_lru-2.0.5-py3-none-any.whl (6.1 kB)\n",
      "Downloading babel-2.17.0-py3-none-any.whl (10.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m176.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Downloading json5-0.12.1-py3-none-any.whl (36 kB)\n",
      "Downloading jsonschema-4.25.1-py3-none-any.whl (90 kB)\n",
      "Downloading attrs-25.4.0-py3-none-any.whl (67 kB)\n",
      "Downloading jsonschema_specifications-2025.9.1-py3-none-any.whl (18 kB)\n",
      "Downloading jupyter_events-0.12.0-py3-none-any.whl (19 kB)\n",
      "Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading jupyter_lsp-2.3.0-py3-none-any.whl (76 kB)\n",
      "Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl (13 kB)\n",
      "Downloading nbconvert-7.16.6-py3-none-any.whl (258 kB)\n",
      "Downloading mistune-3.1.4-py3-none-any.whl (53 kB)\n",
      "Downloading bleach-6.3.0-py3-none-any.whl (164 kB)\n",
      "Downloading tinycss2-1.4.0-py3-none-any.whl (26 kB)\n",
      "Downloading nbclient-0.10.2-py3-none-any.whl (25 kB)\n",
      "Downloading nbformat-5.10.4-py3-none-any.whl (78 kB)\n",
      "Downloading fastjsonschema-2.21.2-py3-none-any.whl (24 kB)\n",
      "Downloading notebook_shim-0.2.4-py3-none-any.whl (13 kB)\n",
      "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Downloading pandocfilters-1.5.1-py2.py3-none-any.whl (8.7 kB)\n",
      "Downloading prometheus_client-0.23.1-py3-none-any.whl (61 kB)\n",
      "Downloading python_json_logger-4.0.0-py3-none-any.whl (15 kB)\n",
      "Downloading pyyaml-6.0.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (806 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m806.6/806.6 kB\u001b[0m \u001b[31m119.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading referencing-0.37.0-py3-none-any.whl (26 kB)\n",
      "Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n",
      "Downloading rfc3987_syntax-1.1.0-py3-none-any.whl (8.0 kB)\n",
      "Downloading lark-1.3.1-py3-none-any.whl (113 kB)\n",
      "Downloading rpds_py-0.28.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (382 kB)\n",
      "Downloading Send2Trash-1.8.3-py3-none-any.whl (18 kB)\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading terminado-0.18.1-py3-none-any.whl (14 kB)\n",
      "Downloading webcolors-24.11.1-py3-none-any.whl (14 kB)\n",
      "Downloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Downloading websocket_client-1.9.0-py3-none-any.whl (82 kB)\n",
      "Downloading argon2_cffi_bindings-25.1.0-cp39-abi3-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl (87 kB)\n",
      "Downloading cffi-2.0.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (215 kB)\n",
      "Downloading beautifulsoup4-4.14.2-py3-none-any.whl (106 kB)\n",
      "Downloading soupsieve-2.8-py3-none-any.whl (36 kB)\n",
      "Downloading defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "Downloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
      "Downloading isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
      "Downloading arrow-1.4.0-py3-none-any.whl (68 kB)\n",
      "Downloading jupyterlab_pygments-0.3.0-py3-none-any.whl (15 kB)\n",
      "Using cached namex-0.1.0-py3-none-any.whl (5.9 kB)\n",
      "Using cached notebook-7.4.7-py3-none-any.whl (14.3 MB)\n",
      "Downloading optree-0.17.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (402 kB)\n",
      "Downloading pycparser-2.23-py3-none-any.whl (118 kB)\n",
      "Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
      "Using cached rich-14.2.0-py3-none-any.whl (243 kB)\n",
      "Using cached markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading uri_template-1.3.0-py3-none-any.whl (11 kB)\n",
      "Installing collected packages: webencodings, pytz, namex, libclang, flatbuffers, fastjsonschema, wrapt, widgetsnbextension, websocket-client, webcolors, urllib3, uri-template, tzdata, tqdm, tinycss2, threadpoolctl, terminado, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, soupsieve, sniffio, send2trash, rpds-py, rfc3986-validator, rfc3339-validator, pyyaml, python-json-logger, pyparsing, pycparser, protobuf, prometheus-client, Pillow, pandocfilters, overrides, optree, opt-einsum, numpy, mistune, mdurl, MarkupSafe, markdown, lark, kiwisolver, jupyterlab_widgets, jupyterlab-pygments, jsonpointer, json5, joblib, idna, h11, grpcio, google-pasta, gast, fqdn, fonttools, defusedxml, cycler, charset_normalizer, certifi, bleach, babel, attrs, async-lru, astunparse, absl-py, werkzeug, scipy, rfc3987-syntax, requests, referencing, pandas, ml-dtypes, markdown-it-py, jupyter-server-terminals, jinja2, httpcore, h5py, deap, contourpy, cffi, beautifulsoup4, arrow, anyio, tensorboard, scikit-learn, rich, matplotlib, kagglehub, jsonschema-specifications, isoduration, ipywidgets, httpx, argon2-cffi-bindings, seaborn, keras, jupyter-console, jsonschema, argon2-cffi, tensorflow, nbformat, nbclient, jupyter-events, nbconvert, jupyter-server, notebook-shim, jupyterlab-server, jupyter-lsp, jupyterlab, notebook, jupyter\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111/111\u001b[0m [jupyter][notebook]jupyterlab]server]]rver]\n",
      "\u001b[1A\u001b[2KSuccessfully installed MarkupSafe-3.0.3 Pillow-12.0.0 absl-py-2.3.1 anyio-4.11.0 argon2-cffi-25.1.0 argon2-cffi-bindings-25.1.0 arrow-1.4.0 astunparse-1.6.3 async-lru-2.0.5 attrs-25.4.0 babel-2.17.0 beautifulsoup4-4.14.2 bleach-6.3.0 certifi-2025.10.5 cffi-2.0.0 charset_normalizer-3.4.4 contourpy-1.3.3 cycler-0.12.1 deap-1.4.3 defusedxml-0.7.1 fastjsonschema-2.21.2 flatbuffers-25.9.23 fonttools-4.60.1 fqdn-1.5.1 gast-0.6.0 google-pasta-0.2.0 grpcio-1.76.0 h11-0.16.0 h5py-3.15.1 httpcore-1.0.9 httpx-0.28.1 idna-3.11 ipywidgets-8.1.7 isoduration-20.11.0 jinja2-3.1.6 joblib-1.5.2 json5-0.12.1 jsonpointer-3.0.0 jsonschema-4.25.1 jsonschema-specifications-2025.9.1 jupyter-1.1.1 jupyter-console-6.6.3 jupyter-events-0.12.0 jupyter-lsp-2.3.0 jupyter-server-2.17.0 jupyter-server-terminals-0.5.3 jupyterlab-4.4.10 jupyterlab-pygments-0.3.0 jupyterlab-server-2.28.0 jupyterlab_widgets-3.0.15 kagglehub-0.3.13 keras-3.12.0 kiwisolver-1.4.9 lark-1.3.1 libclang-18.1.1 markdown-3.9 markdown-it-py-4.0.0 matplotlib-3.10.7 mdurl-0.1.2 mistune-3.1.4 ml-dtypes-0.3.2 namex-0.1.0 nbclient-0.10.2 nbconvert-7.16.6 nbformat-5.10.4 notebook-7.4.7 notebook-shim-0.2.4 numpy-1.26.4 opt-einsum-3.4.0 optree-0.17.0 overrides-7.7.0 pandas-2.3.3 pandocfilters-1.5.1 prometheus-client-0.23.1 protobuf-4.25.8 pycparser-2.23 pyparsing-3.2.5 python-json-logger-4.0.0 pytz-2025.2 pyyaml-6.0.3 referencing-0.37.0 requests-2.32.5 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 rfc3987-syntax-1.1.0 rich-14.2.0 rpds-py-0.28.0 scikit-learn-1.7.2 scipy-1.16.3 seaborn-0.13.2 send2trash-1.8.3 sniffio-1.3.1 soupsieve-2.8 tensorboard-2.16.2 tensorboard-data-server-0.7.2 tensorflow-2.16.1 tensorflow-io-gcs-filesystem-0.37.1 termcolor-3.2.0 terminado-0.18.1 threadpoolctl-3.6.0 tinycss2-1.4.0 tqdm-4.67.1 tzdata-2025.2 uri-template-1.3.0 urllib3-2.5.0 webcolors-24.11.1 webencodings-0.5.1 websocket-client-1.9.0 werkzeug-3.1.3 widgetsnbextension-4.0.14 wrapt-2.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 17:50:19.071181: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-10-30 17:50:19.154859: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-10-30 17:50:20.336524: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import os, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import (Input, GlobalAveragePooling2D, GlobalMaxPooling2D,\n",
    "                                     Concatenate, Dense, Reshape, Multiply, Lambda)\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from tensorflow.keras.applications import DenseNet121, ResNet50, EfficientNetB0, InceptionV3\n",
    "from tensorflow.keras.applications.densenet import preprocess_input as pre_densenet\n",
    "from tensorflow.keras.applications.resnet import preprocess_input as pre_resnet\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input as pre_efficientnet\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input as pre_inception\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "🔍 L4 GPU DETECTION & CONFIGURATION\n",
      "======================================================================\n",
      "TensorFlow version: 2.16.1\n",
      "Built with CUDA: True\n",
      "\n",
      "📱 Physical GPUs: []\n",
      "❌ NO GPU DETECTED (running on CPU)\n",
      "If you expect GPU, install CUDA-enabled TF and restart kernel:\n",
      "  !pip install --upgrade tensorflow[and-cuda]==2.15.0\n",
      "\n",
      "🎯 Logical GPU devices: []\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 17:50:25.948343: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "# GPU Detection and Configuration for L4\n",
    "import tensorflow as tf\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"🔍 L4 GPU DETECTION & CONFIGURATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Built with CUDA: {tf.test.is_built_with_cuda()}\")\n",
    "\n",
    "# Check for GPUs\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(f\"\\n📱 Physical GPUs: {gpus}\")\n",
    "\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.set_visible_devices(gpus, 'GPU')\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"✅ {len(gpus)} GPU(s) configured with memory growth\")\n",
    "        # Test GPU matmul\n",
    "        with tf.device('/GPU:0'):\n",
    "            a = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
    "            b = tf.matmul(a, a)\n",
    "        print(\"✅ GPU test computation:\")\n",
    "        print(b.numpy())\n",
    "    except RuntimeError as e:\n",
    "        print(f\"⚠️ GPU configuration warning: {e}\")\n",
    "else:\n",
    "    print(\"❌ NO GPU DETECTED (running on CPU)\")\n",
    "    print(\"If you expect GPU, install CUDA-enabled TF and restart kernel:\")\n",
    "    print(\"  !pip install --upgrade tensorflow[and-cuda]==2.15.0\")\n",
    "\n",
    "# Show logical devices\n",
    "logical = tf.config.list_logical_devices('GPU')\n",
    "print(f\"\\n🎯 Logical GPU devices: {logical}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 NVIDIA/CUDA Diagnostic\n",
      "\n",
      "✅ NVIDIA driver detected:\n",
      "Thu Oct 30 17:50:37 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 570.195.03             Driver Version: 570.195.03     CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA L4                      Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   38C    P8             16W /   72W |       3MiB /  23034MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "\n",
      "\n",
      "🔍 Checking CUDA libraries...\n",
      "✅ libcudart.so found (CUDA runtime)\n",
      "✅ libcublas.so found (CUDA BLAS)\n",
      "\n",
      "💡 If CUDA libraries are missing, install tensorflow[and-cuda]:\n",
      "   !pip install --upgrade tensorflow[and-cuda]==2.15.0\n",
      "   Then RESTART THE KERNEL\n"
     ]
    }
   ],
   "source": [
    "# Quick diagnostic - Run this if GPU not detected\n",
    "# Check NVIDIA driver and CUDA availability\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "print(\"🔍 NVIDIA/CUDA Diagnostic\\n\")\n",
    "\n",
    "# Check nvidia-smi\n",
    "try:\n",
    "    result = subprocess.run(['nvidia-smi'], capture_output=True, text=True, timeout=5)\n",
    "    if result.returncode == 0:\n",
    "        print(\"✅ NVIDIA driver detected:\")\n",
    "        print(result.stdout)\n",
    "    else:\n",
    "        print(\"❌ nvidia-smi failed\")\n",
    "except FileNotFoundError:\n",
    "    print(\"❌ nvidia-smi not found - NVIDIA driver may not be installed\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error running nvidia-smi: {e}\")\n",
    "\n",
    "# Check CUDA libraries\n",
    "print(\"\\n🔍 Checking CUDA libraries...\")\n",
    "try:\n",
    "    import ctypes\n",
    "    ctypes.CDLL('libcudart.so')\n",
    "    print(\"✅ libcudart.so found (CUDA runtime)\")\n",
    "except:\n",
    "    print(\"❌ libcudart.so not found\")\n",
    "    \n",
    "try:\n",
    "    import ctypes\n",
    "    ctypes.CDLL('libcublas.so')\n",
    "    print(\"✅ libcublas.so found (CUDA BLAS)\")\n",
    "except:\n",
    "    print(\"❌ libcublas.so not found\")\n",
    "\n",
    "print(\"\\n💡 If CUDA libraries are missing, install tensorflow[and-cuda]:\")\n",
    "print(\"   !pip install --upgrade tensorflow[and-cuda]==2.15.0\")\n",
    "print(\"   Then RESTART THE KERNEL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nvidia-cudnn-cu12\n",
      "  Downloading nvidia_cudnn_cu12-9.14.0.64-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cublas-cu12 (from nvidia-cudnn-cu12)\n",
      "  Downloading nvidia_cublas_cu12-12.9.1.4-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Downloading nvidia_cudnn_cu12-9.14.0.64-py3-none-manylinux_2_27_x86_64.whl (647.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m647.1/647.1 MB\u001b[0m \u001b[31m78.7 MB/s\u001b[0m  \u001b[33m0:00:05\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.9.1.4-py3-none-manylinux_2_27_x86_64.whl (581.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m581.2/581.2 MB\u001b[0m \u001b[31m56.7 MB/s\u001b[0m  \u001b[33m0:00:06\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-cublas-cu12, nvidia-cudnn-cu12\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [nvidia-cudnn-cu12]nvidia-cudnn-cu12]\n",
      "\u001b[1A\u001b[2KSuccessfully installed nvidia-cublas-cu12-12.9.1.4 nvidia-cudnn-cu12-9.14.0.64\n"
     ]
    }
   ],
   "source": [
    "!pip install nvidia-cudnn-cu12  # If needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available: 0\n",
      "GPU computation successful: tf.Tensor(\n",
      "[[1. 3.]\n",
      " [3. 7.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Check GPU availability\n",
    "print(\"Num GPUs Available:\", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "# Test GPU computation\n",
    "with tf.device('/GPU:0'):\n",
    "    a = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
    "    b = tf.constant([[1.0, 1.0], [0.0, 1.0]])\n",
    "    c = tf.matmul(a, b)\n",
    "    print(\"GPU computation successful:\", c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ No GPU detected - Running on CPU\n",
      "   If you expect GPU, please:\n",
      "   1. Run the diagnostic cell above\n",
      "   2. Install: !pip install tensorflow[and-cuda]==2.15.0\n",
      "   3. Restart kernel\n",
      "   Batch size reduced to 24 for CPU\n",
      "\n",
      "📋 Configuration:\n",
      "   Data Directory: /teamspace/studios/this_studio/lung_cancer/dataset/lung_image_sets\n",
      "   Image Size: (224, 224)\n",
      "   Batch Size: 24\n",
      "   Random Seed: 42\n"
     ]
    }
   ],
   "source": [
    "# Configuration and Data Setup - OPTIMIZED FOR L4 GPU\n",
    "DATA_DIR   = \"/teamspace/studios/this_studio/lung_cancer/dataset/lung_image_sets\"  # << set this\n",
    "IMG_SIZE   = (224, 224)\n",
    "BATCH_SIZE = 64  # OPTIMIZED: Increased from 24 for L4 GPU (16GB VRAM)\n",
    "SEED       = 42\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# Check if GPU is available before enabling optimizations\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "    print(f'✅ {len(gpus)} GPU(s) detected - Enabling GPU optimizations')\n",
    "    \n",
    "    try:\n",
    "        # Enable memory growth to prevent OOM errors\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print('✅ GPU memory growth enabled')\n",
    "    except RuntimeError as e:\n",
    "        print(f'⚠️ GPU config warning: {e}')\n",
    "    \n",
    "    # OPTIMIZATION: Enable mixed precision for 2-3x speedup on L4\n",
    "    from tensorflow.keras import mixed_precision\n",
    "    policy = mixed_precision.Policy('mixed_float16')\n",
    "    mixed_precision.set_global_policy(policy)\n",
    "    print('✅ Mixed precision enabled (float16 compute, float32 variables)')\n",
    "    \n",
    "    print(f\"🚀 L4 GPU Configuration:\")\n",
    "    print(f\"   • Batch Size: {BATCH_SIZE} (optimized for L4 16GB VRAM)\")\n",
    "    print(f\"   • Mixed Precision: Enabled\")\n",
    "    print(f\"   • Memory Growth: Enabled\")\n",
    "else:\n",
    "    print('⚠️ No GPU detected - Running on CPU')\n",
    "    print('   If you expect GPU, please:')\n",
    "    print('   1. Run the diagnostic cell above')\n",
    "    print('   2. Install: !pip install tensorflow[and-cuda]==2.15.0')\n",
    "    print('   3. Restart kernel')\n",
    "    BATCH_SIZE = 24  # Reduce batch size for CPU\n",
    "    print(f'   Batch size reduced to {BATCH_SIZE} for CPU')\n",
    "\n",
    "print(f\"\\n📋 Configuration:\")\n",
    "print(f\"   Data Directory: {DATA_DIR}\")\n",
    "print(f\"   Image Size: {IMG_SIZE}\")\n",
    "print(f\"   Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"   Random Seed: {SEED}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of attention heads for multi-head channel attention\n",
    "NUM_ATTENTION_HEADS = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12000 images belonging to 3 classes.\n",
      "Found 3000 images belonging to 3 classes.\n",
      "Classes: {'lung_aca': 0, 'lung_n': 1, 'lung_scc': 2}\n",
      "Number of classes: 3\n",
      "Training samples: 12000\n",
      "Validation samples: 3000\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    validation_split=0.20,\n",
    "    rotation_range=20,\n",
    "    horizontal_flip=True,\n",
    "    # IMPORTANT: no rescale here, since we feed raw to model-specific preprocessors\n",
    ")\n",
    "\n",
    "def make_gen(subset):\n",
    "    return train_datagen.flow_from_directory(\n",
    "        DATA_DIR,\n",
    "        target_size=IMG_SIZE,\n",
    "        class_mode='categorical',\n",
    "        batch_size=BATCH_SIZE,\n",
    "        subset=subset,\n",
    "        seed=SEED,\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "train_gen = make_gen('training')\n",
    "val_gen   = make_gen('validation')\n",
    "num_classes = train_gen.num_classes\n",
    "class_indices = train_gen.class_indices\n",
    "id2label = {v:k for k,v in class_indices.items()}\n",
    "\n",
    "print(\"Classes:\", class_indices)\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "print(f\"Training samples: {train_gen.samples}\")\n",
    "print(f\"Validation samples: {val_gen.samples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "GPU CONFIGURATION\n",
      "============================================================\n",
      "✗ No GPU detected - will use CPU\n",
      "\n",
      "TensorFlow: 2.16.1\n",
      "CUDA support: True\n",
      "============================================================\n",
      "\n",
      "✓ Multi-head attention block ready (GPU-optimized)!\n"
     ]
    }
   ],
   "source": [
    "# Channel Attention (Multi-Headed) Implementation - GPU OPTIMIZED\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer, Dense\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"GPU CONFIGURATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"✓ {len(gpus)} GPU(s) detected and configured\")\n",
    "        print(f\"  Devices: {[gpu.name for gpu in gpus]}\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"✗ GPU configuration error: {e}\")\n",
    "else:\n",
    "    print(\"✗ No GPU detected - will use CPU\")\n",
    "\n",
    "print(f\"\\nTensorFlow: {tf.__version__}\")\n",
    "print(f\"CUDA support: {tf.test.is_built_with_cuda()}\")\n",
    "print(\"=\" * 60 + \"\\n\")\n",
    "\n",
    "class MultiHeadChannelAttention(Layer):\n",
    "    def __init__(self, num_heads=4, reduction=16, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_heads = num_heads\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.channel = input_shape[-1]\n",
    "        reduced_channels = max(self.channel // self.reduction, 1)\n",
    "        self.dense1 = Dense(self.num_heads * reduced_channels, activation='relu', name=f'{self.name}_d1')\n",
    "        self.dense2 = Dense(self.num_heads * self.channel, name=f'{self.name}_d2')\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        batch_size = tf.shape(x)[0]\n",
    "        gap = tf.reduce_mean(x, axis=[1,2])\n",
    "        gmp = tf.reduce_max(x, axis=[1,2])\n",
    "        gap_feat = self.dense1(gap)\n",
    "        gmp_feat = self.dense1(gmp)\n",
    "        gap_attn = self.dense2(gap_feat)\n",
    "        gmp_attn = self.dense2(gmp_feat)\n",
    "        combined = tf.reshape(gap_attn + gmp_attn, [batch_size, self.num_heads, self.channel])\n",
    "        attention = tf.nn.sigmoid(tf.reduce_mean(combined, axis=1))\n",
    "        attention = tf.reshape(attention, [batch_size, 1, 1, self.channel])\n",
    "        return x * attention\n",
    "\n",
    "\n",
    "def multi_head_attention_block(x, reduction=16, name=None):\n",
    "    NUM_ATTENTION_HEADS = 4\n",
    "    return MultiHeadChannelAttention(num_heads=NUM_ATTENTION_HEADS, reduction=reduction, name=name)(x)\n",
    "\n",
    "print(\"✓ Multi-head attention block ready (GPU-optimized)!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Lane function ready with GPU-optimized multi-head attention!\n"
     ]
    }
   ],
   "source": [
    "# Lane function with GPU-accelerated backbones\n",
    "from tensorflow.keras.layers import Lambda, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications import ResNet50, DenseNet121, EfficientNetB0, InceptionV3\n",
    "\n",
    "def lane(tensor, backbone=\"resnet\", reduction=16):\n",
    "    \"\"\"Create a processing lane for each CNN backbone with multi-head channel attention (GPU-optimized)\"\"\"\n",
    "    if backbone == \"resnet\":\n",
    "        x = Lambda(pre_resnet, name=\"pre_resnet\")(tensor)\n",
    "        x = ResNet50(include_top=False, weights='imagenet')(x)\n",
    "    elif backbone == \"densenet\":\n",
    "        x = Lambda(pre_densenet, name=\"pre_densenet\")(tensor)\n",
    "        x = DenseNet121(include_top=False, weights='imagenet')(x)\n",
    "    elif backbone == \"efficientnet\":\n",
    "        x = Lambda(pre_efficientnet, name=\"pre_efficientnet\")(tensor)\n",
    "        x = EfficientNetB0(include_top=False, weights='imagenet')(x)\n",
    "    elif backbone == \"inception\":\n",
    "        x = Lambda(pre_inception, name=\"pre_inception\")(tensor)\n",
    "        x = InceptionV3(include_top=False, weights='imagenet')(x)\n",
    "    else:\n",
    "        raise ValueError(f'Unknown backbone: {backbone}')\n",
    "    \n",
    "    x = multi_head_attention_block(x, reduction=reduction, name=f\"mhca_{backbone}\")\n",
    "    x = GlobalAveragePooling2D(name=f\"gap_{backbone}\")(x)\n",
    "    return x\n",
    "\n",
    "print(\"✓ Lane function ready with GPU-optimized multi-head attention!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building multi-backbone feature concatenator with multi-head attention...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m29084464/29084464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
      "\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m87910968/87910968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
      "Feature extractor built successfully!\n",
      "Feature dimension: 6400\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ pre_densenet        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ pre_resnet (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ pre_efficientnet    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ pre_inception       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ densenet121         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">7,037,504</span> │ pre_densenet[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ resnet50            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> │ pre_resnet[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ efficientnetb0      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">4,049,571</span> │ pre_efficientnet… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ inception_v3        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>,      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">21,802,784</span> │ pre_inception[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mhca_densenet       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,315,072</span> │ densenet121[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadChannelA…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mhca_resnet         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">5,251,584</span> │ resnet50[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadChannelA…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mhca_efficientnet   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,053,440</span> │ efficientnetb0[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadChannelA…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mhca_inception      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>,      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">5,251,584</span> │ inception_v3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadChannelA…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gap_densenet        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ mhca_densenet[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gap_resnet          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ mhca_resnet[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gap_efficientnet    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ mhca_efficientne… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gap_inception       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ mhca_inception[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concat_feats        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6400</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ gap_densenet[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ gap_resnet[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│                     │                   │            │ gap_efficientnet… │\n",
       "│                     │                   │            │ gap_inception[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ pre_densenet        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mLambda\u001b[0m)            │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ pre_resnet (\u001b[38;5;33mLambda\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│                     │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ pre_efficientnet    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mLambda\u001b[0m)            │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ pre_inception       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mLambda\u001b[0m)            │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ densenet121         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m,      │  \u001b[38;5;34m7,037,504\u001b[0m │ pre_densenet[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mFunctional\u001b[0m)        │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ resnet50            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m,      │ \u001b[38;5;34m23,587,712\u001b[0m │ pre_resnet[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mFunctional\u001b[0m)        │ \u001b[38;5;34m2048\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ efficientnetb0      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m,      │  \u001b[38;5;34m4,049,571\u001b[0m │ pre_efficientnet… │\n",
       "│ (\u001b[38;5;33mFunctional\u001b[0m)        │ \u001b[38;5;34m1280\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ inception_v3        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m,      │ \u001b[38;5;34m21,802,784\u001b[0m │ pre_inception[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mFunctional\u001b[0m)        │ \u001b[38;5;34m2048\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mhca_densenet       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m,      │  \u001b[38;5;34m1,315,072\u001b[0m │ densenet121[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mMultiHeadChannelA…\u001b[0m │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mhca_resnet         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m,      │  \u001b[38;5;34m5,251,584\u001b[0m │ resnet50[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mMultiHeadChannelA…\u001b[0m │ \u001b[38;5;34m2048\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mhca_efficientnet   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m,      │  \u001b[38;5;34m2,053,440\u001b[0m │ efficientnetb0[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mMultiHeadChannelA…\u001b[0m │ \u001b[38;5;34m1280\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mhca_inception      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m,      │  \u001b[38;5;34m5,251,584\u001b[0m │ inception_v3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mMultiHeadChannelA…\u001b[0m │ \u001b[38;5;34m2048\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gap_densenet        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ mhca_densenet[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gap_resnet          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ mhca_resnet[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gap_efficientnet    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ mhca_efficientne… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gap_inception       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ mhca_inception[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concat_feats        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6400\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ gap_densenet[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ gap_resnet[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│                     │                   │            │ gap_efficientnet… │\n",
       "│                     │                   │            │ gap_inception[\u001b[38;5;34m0\u001b[0m]… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">70,349,251</span> (268.36 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m70,349,251\u001b[0m (268.36 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">70,136,028</span> (267.55 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m70,136,028\u001b[0m (267.55 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">213,223</span> (832.91 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m213,223\u001b[0m (832.91 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build Feature Extractor Model\n",
    "print(\"Building multi-backbone feature concatenator with multi-head attention...\")\n",
    "\n",
    "# Define input tensor with image size (224x224x3 RGB)\n",
    "inp = Input(shape=(224,224,3))\n",
    "\n",
    "# Extract features from DenseNet lane (multi-head attention)\n",
    "feat_d = lane(inp, \"densenet\", reduction=16)\n",
    "# Extract features from ResNet lane (multi-head attention)\n",
    "feat_r = lane(inp, \"resnet\", reduction=16)\n",
    "# Extract features from EfficientNetB0 lane (multi-head attention)\n",
    "feat_e = lane(inp, \"efficientnet\", reduction=16)\n",
    "# Extract features from InceptionV3 lane (multi-head attention)\n",
    "feat_i = lane(inp, \"inception\", reduction=16)\n",
    "\n",
    "# Concatenate features from all four backbones\n",
    "concat_feat = Concatenate(name=\"concat_feats\")([feat_d, feat_r, feat_e, feat_i])\n",
    "\n",
    "# Create feature extractor model (input → concatenated features)\n",
    "feature_model = Model(inp, concat_feat)\n",
    "\n",
    "# Get final concatenated feature dimension\n",
    "feature_dim = feature_model.output_shape[-1]\n",
    "\n",
    "print(f\"Feature extractor built successfully!\")\n",
    "print(f\"Feature dimension: {feature_dim}\")\n",
    "\n",
    "# Show model summary (layers, parameters, shapes)\n",
    "feature_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ GPU-optimized feature extraction ready!\n"
     ]
    }
   ],
   "source": [
    "# Extract Deep Features with GPU Optimization - OPTIMIZED\n",
    "from math import ceil\n",
    "\n",
    "def extract_features(generator):\n",
    "    \"\"\"Extract features with GPU acceleration and optimized batching\"\"\"\n",
    "    import time\n",
    "    \n",
    "    print(\"🚀 Starting GPU-optimized feature extraction...\")\n",
    "    if tf.config.list_physical_devices('GPU'):\n",
    "        print(\"🔥 Using L4 GPU with mixed precision (if enabled)\")\n",
    "        with tf.device('/GPU:0'):\n",
    "            return _extract_features_impl(generator)\n",
    "    else:\n",
    "        print(\"💻 Using CPU (GPU not available)\")\n",
    "        return _extract_features_impl(generator)\n",
    "\n",
    "def _extract_features_impl(generator):\n",
    "    import time\n",
    "    X, y = [], []\n",
    "    steps = len(generator)\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for i in range(steps):\n",
    "        imgs, labels = next(generator)\n",
    "        feats = feature_model.predict(imgs, verbose=0)\n",
    "        X.append(feats)\n",
    "        y.append(labels)\n",
    "        \n",
    "        if (i + 1) % 20 == 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            avg = elapsed / (i + 1)\n",
    "            eta = (steps - (i + 1)) * avg\n",
    "            print(f\"📊 [{i + 1}/{steps}] Avg batch: {avg:.2f}s | ETA: {eta/60:.1f}m\")\n",
    "    \n",
    "    total = time.time() - start_time\n",
    "    print(f\"✅ Feature extraction: {total/60:.2f} min ({total/steps:.2f}s/batch)\")\n",
    "    return np.vstack(X), np.vstack(y)\n",
    "\n",
    "print(\"✅ GPU-optimized feature extraction ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting training features …\n",
      "🚀 Starting GPU-optimized feature extraction...\n",
      "💻 Using CPU (GPU not available)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 [20/500] Avg batch: 3.01s | ETA: 24.1m\n",
      "📊 [40/500] Avg batch: 2.69s | ETA: 20.6m\n",
      "📊 [60/500] Avg batch: 2.58s | ETA: 18.9m\n",
      "📊 [80/500] Avg batch: 2.51s | ETA: 17.6m\n",
      "📊 [100/500] Avg batch: 2.49s | ETA: 16.6m\n",
      "📊 [120/500] Avg batch: 2.46s | ETA: 15.6m\n",
      "📊 [140/500] Avg batch: 2.43s | ETA: 14.6m\n",
      "📊 [160/500] Avg batch: 2.41s | ETA: 13.7m\n",
      "📊 [180/500] Avg batch: 2.39s | ETA: 12.7m\n",
      "📊 [200/500] Avg batch: 2.37s | ETA: 11.8m\n",
      "📊 [220/500] Avg batch: 2.35s | ETA: 11.0m\n",
      "📊 [240/500] Avg batch: 2.34s | ETA: 10.1m\n",
      "📊 [260/500] Avg batch: 2.32s | ETA: 9.3m\n",
      "📊 [280/500] Avg batch: 2.31s | ETA: 8.5m\n",
      "📊 [300/500] Avg batch: 2.30s | ETA: 7.7m\n",
      "📊 [320/500] Avg batch: 2.29s | ETA: 6.9m\n",
      "📊 [340/500] Avg batch: 2.30s | ETA: 6.1m\n",
      "📊 [360/500] Avg batch: 2.29s | ETA: 5.3m\n",
      "📊 [380/500] Avg batch: 2.28s | ETA: 4.6m\n",
      "📊 [400/500] Avg batch: 2.29s | ETA: 3.8m\n",
      "📊 [420/500] Avg batch: 2.29s | ETA: 3.1m\n",
      "📊 [440/500] Avg batch: 2.29s | ETA: 2.3m\n",
      "📊 [460/500] Avg batch: 2.28s | ETA: 1.5m\n",
      "📊 [480/500] Avg batch: 2.28s | ETA: 0.8m\n",
      "📊 [500/500] Avg batch: 2.28s | ETA: 0.0m\n",
      "✅ Feature extraction: 18.99 min (2.28s/batch)\n",
      "Training features shape: (12000, 6400)\n",
      "Training labels shape: (12000, 3)\n"
     ]
    }
   ],
   "source": [
    "# Extract Training Features\n",
    "print(\"Extracting training features …\")\n",
    "X_tr, Y_tr_ohe = extract_features(train_gen)\n",
    "print(f\"Training features shape: {X_tr.shape}\")\n",
    "print(f\"Training labels shape: {Y_tr_ohe.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: pymrmr not available. Install with: conda install pymrmr -c conda-forge\n",
      "Falling back to mutual information ranking only.\n",
      "✅ Optimized mRMR feature selection ready!\n",
      "✅ Optimized AGWO feature selection ready!\n"
     ]
    }
   ],
   "source": [
    "## 1. TRUE mRMR Feature Ranking - OPTIMIZED\n",
    "try:\n",
    "    import pymrmr\n",
    "    print(\"pymrmr imported successfully\")\n",
    "except ImportError:\n",
    "    print(\"WARNING: pymrmr not available. Install with: conda install pymrmr -c conda-forge\")\n",
    "    print(\"Falling back to mutual information ranking only.\")\n",
    "    pymrmr = None\n",
    "\n",
    "import numpy as np, pandas as pd, time, gc\n",
    "from sklearn.feature_selection import mutual_info_classif, VarianceThreshold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def true_mrmr_feature_selection(X, y_ohe, n_features=1000, sample_rows=1500, var_thresh=0.01):\n",
    "    \"\"\"\n",
    "    OPTIMIZED TRUE mRMR implementation with reduced sampling\n",
    "    \"\"\"\n",
    "    t0 = time.time()\n",
    "    y = np.argmax(y_ohe, axis=1)\n",
    "    n_samples, n_feats = X.shape\n",
    "    \n",
    "    # Variance filter to remove low-variance features\n",
    "    if var_thresh > 0:\n",
    "        vt = VarianceThreshold(var_thresh)\n",
    "        X_filtered = vt.fit_transform(X)\n",
    "        kept_indices = np.where(vt.get_support())[0]\n",
    "    else:\n",
    "        X_filtered = X\n",
    "        kept_indices = np.arange(n_feats)\n",
    "    \n",
    "    print(f\"[mRMR] After variance filter: {len(kept_indices)} features\")\n",
    "    \n",
    "    # OPTIMIZATION: Reduced row sampling for speed\n",
    "    if sample_rows and sample_rows < X_filtered.shape[0]:\n",
    "        rng = np.random.default_rng(42)\n",
    "        rows = rng.choice(X_filtered.shape[0], size=sample_rows, replace=False)\n",
    "        X_sample = X_filtered[rows]\n",
    "        y_sample = y[rows]\n",
    "    else:\n",
    "        X_sample = X_filtered\n",
    "        y_sample = y\n",
    "    \n",
    "    # Apply TRUE mRMR if available, otherwise fall back to MI\n",
    "    if pymrmr is not None:\n",
    "        try:\n",
    "            # Create DataFrame for pymrmr\n",
    "            feature_names = [f'feature_{i}' for i in range(X_sample.shape[1])]\n",
    "            df = pd.DataFrame(X_sample, columns=feature_names)\n",
    "            df['target'] = y_sample\n",
    "            \n",
    "            selected_features = pymrmr.mRMR(df, 'MIQ', n_features)\n",
    "            # Convert feature names back to indices\n",
    "            selected_indices = [int(f.split('_')[1]) for f in selected_features]\n",
    "            # Map back to original feature indices\n",
    "            final_indices = [kept_indices[i] for i in selected_indices]\n",
    "            \n",
    "            print(f\"[TRUE-mRMR] Selected {len(final_indices)} features in {time.time()-t0:.2f}s\")\n",
    "            return final_indices\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"[TRUE-mRMR] Error: {e}. Falling back to mutual information ranking.\")\n",
    "            \n",
    "    # Fallback to MI-based ranking\n",
    "    mi_scores = mutual_info_classif(X_sample, y_sample, discrete_features=False, random_state=42, n_jobs=-1)\n",
    "    ranked_indices = np.argsort(mi_scores)[::-1]\n",
    "    selected_indices = ranked_indices[:n_features]\n",
    "    final_indices = [kept_indices[i] for i in selected_indices]\n",
    "    \n",
    "    print(f\"[MI-Ranking] Selected {len(final_indices)} features in {time.time()-t0:.2f}s\")\n",
    "    return final_indices\n",
    "\n",
    "print(\"✅ Optimized mRMR feature selection ready!\")\n",
    "\n",
    "\n",
    "## 2. Enhanced Adaptive Grey Wolf Optimization (AGWO) - OPTIMIZED\n",
    "import numpy as np, gc, hashlib\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def _subset_hash(idxs):\n",
    "    return hashlib.md5(np.asarray(idxs, dtype=np.int32).tobytes()).hexdigest()\n",
    "\n",
    "def enhanced_agwo_feature_selection(\n",
    "    X_ranked,\n",
    "    y_ohe,\n",
    "    ranked_global_indices,\n",
    "    n_wolves=20,  # OPTIMIZED: Reduced from 25\n",
    "    n_iter=15,    # OPTIMIZED: Reduced from 30 with better convergence\n",
    "    min_subset=500,\n",
    "    max_subset=1500,  # OPTIMIZED: Reduced from 2000\n",
    "    row_sample=2500,  # OPTIMIZED: Reduced from 3000\n",
    "    knn_folds=3,      # OPTIMIZED: Reduced from 5\n",
    "    rf_folds=2,       # OPTIMIZED: Kept at 2\n",
    "    rf_max_features=400,  # OPTIMIZED: Reduced from 500\n",
    "    penalty_weight=0.015,  # OPTIMIZED: Fine-tuned\n",
    "    patience=6,           # OPTIMIZED: Reduced from 8\n",
    "    random_state=42,\n",
    "    verbose=True\n",
    "):\n",
    "    \"\"\"\n",
    "    OPTIMIZED Enhanced AGWO with reduced iterations and better convergence\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    y = np.argmax(y_ohe, axis=1)\n",
    "    n_samples, n_feats = X_ranked.shape\n",
    "\n",
    "    # Enhanced row subsampling (stratified)\n",
    "    if row_sample and row_sample < n_samples:\n",
    "        rows = []\n",
    "        per_class = row_sample // len(np.unique(y))\n",
    "        for cls in np.unique(y):\n",
    "            cls_idx = np.where(y == cls)[0]\n",
    "            take = min(per_class, len(cls_idx))\n",
    "            rows.append(rng.choice(cls_idx, size=take, replace=False))\n",
    "        rows = np.concatenate(rows)\n",
    "    else:\n",
    "        rows = np.arange(n_samples)\n",
    "\n",
    "    X_fit = X_ranked[rows]\n",
    "    y_fit = y[rows]\n",
    "\n",
    "    # Wolves initialization with better diversity\n",
    "    def init_position():\n",
    "        vals = rng.random(n_feats)\n",
    "        vals = vals * (1 + 0.5 * np.sin(np.arange(n_feats) * 0.1))\n",
    "        return vals\n",
    "\n",
    "    wolves = [init_position() for _ in range(n_wolves)]\n",
    "\n",
    "    # OPTIMIZED: Logarithmic growth with steeper curve\n",
    "    def subset_budget(iter_idx):\n",
    "        log_factor = np.log(iter_idx + 2) / np.log(n_iter + 1)\n",
    "        return int(min_subset + (max_subset - min_subset) * log_factor)\n",
    "\n",
    "    # Enhanced fitness cache\n",
    "    fitness_cache = {}\n",
    "\n",
    "    def eval_subset(local_idx):\n",
    "        if len(local_idx) < 2:\n",
    "            return 0.0\n",
    "        key_hash = _subset_hash(local_idx)\n",
    "        if key_hash in fitness_cache:\n",
    "            return fitness_cache[key_hash]\n",
    "\n",
    "        # Enhanced feature selection for RF\n",
    "        feat_slice = local_idx\n",
    "        if len(feat_slice) > rf_max_features:\n",
    "            feat_slice_rf = rng.choice(feat_slice, size=rf_max_features, replace=False)\n",
    "        else:\n",
    "            feat_slice_rf = feat_slice\n",
    "\n",
    "        X_sub = X_fit[:, feat_slice]\n",
    "        scaler = StandardScaler()\n",
    "        X_sub = scaler.fit_transform(X_sub)\n",
    "\n",
    "        # KNN CV with reduced folds\n",
    "        skf_knn = StratifiedKFold(n_splits=knn_folds, shuffle=True, random_state=123)\n",
    "        knn_scores = []\n",
    "        knn = KNeighborsClassifier(n_neighbors=5, weights='distance', n_jobs=-1)\n",
    "        for tr, va in skf_knn.split(X_sub, y_fit):\n",
    "            knn.fit(X_sub[tr], y_fit[tr])\n",
    "            pred = knn.predict(X_sub[va])\n",
    "            knn_scores.append(accuracy_score(y_fit[va], pred))\n",
    "        knn_acc = np.mean(knn_scores)\n",
    "\n",
    "        # RF CV with reduced folds\n",
    "        X_sub_rf = X_fit[:, feat_slice_rf]\n",
    "        scaler_rf = StandardScaler()\n",
    "        X_sub_rf = scaler_rf.fit_transform(X_sub_rf)\n",
    "        skf_rf = StratifiedKFold(n_splits=rf_folds, shuffle=True, random_state=321)\n",
    "        rf_scores = []\n",
    "        rf = RandomForestClassifier(\n",
    "            n_estimators=150,  # OPTIMIZED: Reduced from 200\n",
    "            max_features='sqrt',\n",
    "            n_jobs=-1,\n",
    "            random_state=999\n",
    "        )\n",
    "        for tr, va in skf_rf.split(X_sub_rf, y_fit):\n",
    "            rf.fit(X_sub_rf[tr], y_fit[tr])\n",
    "            pred = rf.predict(X_sub_rf[va])\n",
    "            rf_scores.append(accuracy_score(y_fit[va], pred))\n",
    "        rf_acc = np.mean(rf_scores)\n",
    "\n",
    "        # Fine-tuned penalty\n",
    "        size_penalty = penalty_weight * (len(local_idx) / max_subset)\n",
    "        fitness = 0.7 * knn_acc + 0.3 * rf_acc - size_penalty\n",
    "        fitness_cache[key_hash] = fitness\n",
    "        return fitness\n",
    "\n",
    "    # Enhanced decoding with stability\n",
    "    def decode(position, k):\n",
    "        noisy_pos = position + rng.normal(0, 0.01, len(position))\n",
    "        order = np.argpartition(noisy_pos, -k)[-k:]\n",
    "        return order[np.argsort(-noisy_pos[order])]\n",
    "\n",
    "    # Enhanced AGWO loop\n",
    "    best_global_subset = None\n",
    "    best_fitness = -1\n",
    "    no_improve = 0\n",
    "\n",
    "    for it in range(n_iter):\n",
    "        k_budget = subset_budget(it)\n",
    "\n",
    "        # Decode all wolves\n",
    "        wolf_subsets = [decode(w, k_budget) for w in wolves]\n",
    "        wolf_scores = [eval_subset(sub) for sub in wolf_subsets]\n",
    "\n",
    "        # Identify alpha, beta, delta\n",
    "        order = np.argsort(wolf_scores)[::-1]\n",
    "        alpha, beta, delta = wolves[order[0]], wolves[order[1]], wolves[order[2]]\n",
    "        alpha_subset = wolf_subsets[order[0]]\n",
    "        alpha_score = wolf_scores[order[0]]\n",
    "\n",
    "        if alpha_score > best_fitness:\n",
    "            best_fitness = alpha_score\n",
    "            best_global_subset = alpha_subset.copy()\n",
    "            no_improve = 0\n",
    "        else:\n",
    "            no_improve += 1\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"[AGWO] iter {it+1}/{n_iter} k={k_budget} alpha={alpha_score:.4f} best={best_fitness:.4f} cache={len(fitness_cache)}\")\n",
    "\n",
    "        if no_improve >= patience:\n",
    "            if verbose:\n",
    "                print(f\"[AGWO] Early stop (patience {patience})\")\n",
    "            break\n",
    "\n",
    "        # OPTIMIZED: Steeper decay for faster convergence\n",
    "        a = 2 * np.exp(-4 * (it / n_iter))\n",
    "\n",
    "        # Enhanced wolf update\n",
    "        new_wolves = []\n",
    "        for idx, w in enumerate(wolves):\n",
    "            if idx in order[:3]:\n",
    "                new_wolves.append(w)\n",
    "                continue\n",
    "                \n",
    "            A1 = 2 * a * rng.random(n_feats) - a\n",
    "            C1 = 2 * rng.random(n_feats)\n",
    "            A2 = 2 * a * rng.random(n_feats) - a\n",
    "            C2 = 2 * rng.random(n_feats)\n",
    "            A3 = 2 * a * rng.random(n_feats) - a\n",
    "            C3 = 2 * rng.random(n_feats)\n",
    "\n",
    "            D_alpha = np.abs(C1 * alpha - w)\n",
    "            D_beta  = np.abs(C2 * beta  - w)\n",
    "            D_delta = np.abs(C3 * delta - w)\n",
    "\n",
    "            X1 = alpha - A1 * D_alpha\n",
    "            X2 = beta  - A2 * D_beta\n",
    "            X3 = delta - A3 * D_delta\n",
    "\n",
    "            new_pos = (X1 + X2 + X3) / 3.0\n",
    "\n",
    "            # Enhanced mutation\n",
    "            if rng.random() < 0.15:\n",
    "                mut_mask = rng.random(n_feats) < 0.005\n",
    "                noise = rng.normal(0, 0.3, np.sum(mut_mask))\n",
    "                new_pos[mut_mask] += noise\n",
    "\n",
    "            new_pos = np.clip(new_pos, -2.0, 2.0)\n",
    "            new_wolves.append(new_pos)\n",
    "\n",
    "        # Diversity injection\n",
    "        if no_improve == patience - 1:\n",
    "            inject_count = max(2, n_wolves // 5)\n",
    "            for _ in range(inject_count):\n",
    "                ridx = rng.integers(3, n_wolves)\n",
    "                new_wolves[ridx] = init_position()\n",
    "\n",
    "        wolves = new_wolves\n",
    "\n",
    "    # Map to global feature indices\n",
    "    selected_global = [ranked_global_indices[i] for i in best_global_subset]\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"[AGWO] Complete: {len(selected_global)} features, fitness={best_fitness:.4f}\")\n",
    "\n",
    "    return selected_global\n",
    "\n",
    "print(\"✅ Optimized AGWO feature selection ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting validation features …\n",
      "🚀 Starting GPU-optimized feature extraction...\n",
      "💻 Using CPU (GPU not available)\n",
      "📊 [20/125] Avg batch: 2.23s | ETA: 3.9m\n",
      "📊 [40/125] Avg batch: 2.23s | ETA: 3.2m\n",
      "📊 [60/125] Avg batch: 2.21s | ETA: 2.4m\n",
      "📊 [80/125] Avg batch: 2.21s | ETA: 1.7m\n",
      "📊 [100/125] Avg batch: 2.21s | ETA: 0.9m\n",
      "📊 [120/125] Avg batch: 2.20s | ETA: 0.2m\n",
      "✅ Feature extraction: 4.59 min (2.20s/batch)\n",
      "Validation features shape: (3000, 6400)\n",
      "Validation labels shape: (3000, 3)\n"
     ]
    }
   ],
   "source": [
    "# Extract Validation Features\n",
    "print(\"Extracting validation features …\")\n",
    "X_va, Y_va_ohe = extract_features(val_gen)\n",
    "print(f\"Validation features shape: {X_va.shape}\")\n",
    "print(f\"Validation labels shape: {Y_va_ohe.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total features shape: (15000, 6400)\n",
      "Total labels shape: (15000,)\n",
      "Classes present: [0 1 2]\n",
      "Class distribution: [5000 5000 5000]\n"
     ]
    }
   ],
   "source": [
    "# Combine Features and Convert Labels\n",
    "# NOTE: We avoid building X_full (memory heavy); use train/val directly where possible\n",
    "X_full = np.vstack([X_tr, X_va])\n",
    "y_full = np.argmax(np.vstack([Y_tr_ohe, Y_va_ohe]), axis=1)\n",
    "\n",
    "print(f\"Total features shape: {X_full.shape}\")\n",
    "print(f\"Total labels shape: {y_full.shape}\")\n",
    "print(f\"Classes present: {np.unique(y_full)}\")\n",
    "print(f\"Class distribution: {np.bincount(y_full)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1: TRUE mRMR Feature Ranking (Optimized)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mRMR] After variance filter: 4003 features\n",
      "[MI-Ranking] Selected 800 features in 8.30s\n",
      "[Pipeline] Ranked features: 800\n",
      "[Pipeline] Ranked features shape: (12000, 800)\n",
      "[Pipeline] Adjusted max_subset: 1500 → 800\n",
      "\n",
      "Stage 3: Enhanced AGWO Feature Selection (Optimized)\n",
      "[AGWO] iter 1/15 k=575 alpha=0.9522 best=0.9522 cache=20\n",
      "[AGWO] iter 2/15 k=618 alpha=0.9526 best=0.9526 cache=40\n",
      "[AGWO] iter 3/15 k=650 alpha=0.9540 best=0.9540 cache=60\n",
      "[AGWO] iter 4/15 k=674 alpha=0.9526 best=0.9540 cache=80\n",
      "[AGWO] iter 5/15 k=693 alpha=0.9516 best=0.9540 cache=100\n",
      "[AGWO] iter 6/15 k=710 alpha=0.9514 best=0.9540 cache=120\n",
      "[AGWO] iter 7/15 k=725 alpha=0.9509 best=0.9540 cache=140\n",
      "[AGWO] iter 8/15 k=737 alpha=0.9502 best=0.9540 cache=160\n",
      "[AGWO] iter 9/15 k=749 alpha=0.9502 best=0.9540 cache=180\n",
      "[AGWO] Early stop (patience 6)\n",
      "[AGWO] Complete: 650 features, fitness=0.9540\n",
      "[Pipeline] Final selected features: 650\n",
      "[Pipeline] Train (12000, 650), Test (3000, 650)\n",
      "[Pipeline] Feature reduction: 6400 → 650 (10.2%)\n",
      "\n",
      "[Pipeline] Total time: 308.36s\n",
      "✅ Optimized two-stage feature selection completed!\n"
     ]
    }
   ],
   "source": [
    "# --- OPTIMIZED: TRUE mRMR + Enhanced AGWO Feature Selection Pipeline ---\n",
    "import time, gc\n",
    "\n",
    "t_total = time.time()\n",
    "\n",
    "# OPTIMIZED Parameters (balanced for speed and accuracy)\n",
    "n_mrmr = 800          # OPTIMIZED: Reduced from 1000\n",
    "sample_rows = 1500    # OPTIMIZED: Reduced from 2000\n",
    "subset_size = 1500    # OPTIMIZED: Reduced from 2000 for AGWO\n",
    "n_wolves = 20         # OPTIMIZED: Reduced from 25\n",
    "n_iter = 15           # OPTIMIZED: Reduced from 30\n",
    "\n",
    "# Stage 1: TRUE mRMR Feature Ranking\n",
    "print(\"Stage 1: TRUE mRMR Feature Ranking (Optimized)\")\n",
    "ranked_features = true_mrmr_feature_selection(\n",
    "    X_tr, Y_tr_ohe,\n",
    "    n_features=n_mrmr,\n",
    "    sample_rows=sample_rows,\n",
    "    var_thresh=0.01\n",
    ")\n",
    "print(f\"[Pipeline] Ranked features: {len(ranked_features)}\")\n",
    "\n",
    "# Stage 2: Slice training matrix to ranked features ONLY for Enhanced AGWO\n",
    "X_tr_ranked = X_tr[:, ranked_features]\n",
    "print(f\"[Pipeline] Ranked features shape: {X_tr_ranked.shape}\")\n",
    "\n",
    "# IMPORTANT FIX: Adjust max_subset to not exceed available features\n",
    "actual_max_subset = min(subset_size, len(ranked_features))\n",
    "print(f\"[Pipeline] Adjusted max_subset: {subset_size} → {actual_max_subset}\")\n",
    "\n",
    "# Stage 3: Enhanced AGWO Feature Selection\n",
    "print(\"\\nStage 3: Enhanced AGWO Feature Selection (Optimized)\")\n",
    "selected_features = enhanced_agwo_feature_selection(\n",
    "    X_tr_ranked, Y_tr_ohe, ranked_features,\n",
    "    n_wolves=n_wolves,\n",
    "    n_iter=n_iter,\n",
    "    min_subset=500,\n",
    "    max_subset=actual_max_subset,  # FIX: Use adjusted value\n",
    "    row_sample=2500,   # OPTIMIZED: Reduced from 3000\n",
    "    knn_folds=3,       # OPTIMIZED: Reduced from 5\n",
    "    rf_folds=2,        # OPTIMIZED: Kept at 2\n",
    "    rf_max_features=400,  # OPTIMIZED: Reduced from 500\n",
    "    penalty_weight=0.015,\n",
    "    patience=6,           # OPTIMIZED: Reduced from 8\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(f\"[Pipeline] Final selected features: {len(selected_features)}\")\n",
    "\n",
    "# Extract final feature matrices\n",
    "X_tr_final = X_tr[:, selected_features]\n",
    "X_va_final = X_va[:, selected_features]\n",
    "\n",
    "# Train/test split on combined (train+val)\n",
    "y_full = np.argmax(np.vstack([Y_tr_ohe, Y_va_ohe]), axis=1)\n",
    "X_full_sel = np.vstack([X_tr_final, X_va_final])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_full_sel, y_full, test_size=0.20, random_state=SEED, stratify=y_full\n",
    ")\n",
    "\n",
    "print(f\"[Pipeline] Train {X_train.shape}, Test {X_test.shape}\")\n",
    "print(f\"[Pipeline] Feature reduction: {X_tr.shape[1]} → {X_tr_final.shape[1]} ({X_tr_final.shape[1]/X_tr.shape[1]:.1%})\")\n",
    "\n",
    "# Cleanup\n",
    "del X_tr_ranked\n",
    "gc.collect()\n",
    "\n",
    "print(f\"\\n[Pipeline] Total time: {time.time() - t_total:.2f}s\")\n",
    "print(\"✅ Optimized two-stage feature selection completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Classifiers initialized (optimized, no XGBoost)\n"
     ]
    }
   ],
   "source": [
    "# Initialize Classifiers - OPTIMIZED (No XGBoost to avoid extra dependency)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5, weights='distance', n_jobs=-1)\n",
    "svm = SVC(kernel='rbf', probability=True, C=1.0, gamma='scale', random_state=SEED, cache_size=500)\n",
    "rf  = RandomForestClassifier(n_estimators=250, random_state=SEED, n_jobs=-1, max_features='sqrt')\n",
    "lr  = LogisticRegression(max_iter=500, random_state=SEED, n_jobs=-1, solver='saga')\n",
    "\n",
    "print(\"✅ Classifiers initialized (optimized, no XGBoost)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classifiers …\n",
      "  Training KNN...\n",
      "  Training SVM...\n",
      "  Training Random Forest...\n",
      "  Training Logistic Regression...\n",
      "All classifiers trained successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/teamspace/studios/this_studio/.conda/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Train Classifiers\n",
    "print(\"Training classifiers …\")\n",
    "\n",
    "print(\"  Training KNN...\")\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "print(\"  Training SVM...\")\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "print(\"  Training Random Forest...\")\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "print(\"  Training Logistic Regression...\")\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "print(\"All classifiers trained successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n",
      "Predictions completed!\n"
     ]
    }
   ],
   "source": [
    "# Make Predictions\n",
    "print(\"Making predictions...\")\n",
    "\n",
    "knn_pred = knn.predict(X_test)\n",
    "svm_pred = svm.predict(X_test)\n",
    "rf_pred  = rf.predict(X_test)\n",
    "lr_pred  = lr.predict(X_test)\n",
    "\n",
    "# Probabilistic predictions (for ensemble if needed)\n",
    "knn_proba = knn.predict_proba(X_test) if hasattr(knn, 'predict_proba') else None\n",
    "svm_proba = svm.predict_proba(X_test) if hasattr(svm, 'predict_proba') else None\n",
    "rf_proba  = rf.predict_proba(X_test) if hasattr(rf, 'predict_proba') else None\n",
    "lr_proba  = lr.predict_proba(X_test) if hasattr(lr, 'predict_proba') else None\n",
    "\n",
    "print(\"Predictions completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual Classifier Accuracies:\n",
      "  KNN: 0.9953\n",
      "  SVM: 0.9887\n",
      "  RF : 0.9733\n",
      "  LR : 0.9820\n",
      "\n",
      "=== KNN Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    lung_aca       1.00      0.99      0.99      1000\n",
      "      lung_n       1.00      1.00      1.00      1000\n",
      "    lung_scc       0.99      1.00      0.99      1000\n",
      "\n",
      "    accuracy                           1.00      3000\n",
      "   macro avg       1.00      1.00      1.00      3000\n",
      "weighted avg       1.00      1.00      1.00      3000\n",
      "\n",
      "\n",
      "=== SVM Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    lung_aca       0.98      0.98      0.98      1000\n",
      "      lung_n       1.00      1.00      1.00      1000\n",
      "    lung_scc       0.98      0.98      0.98      1000\n",
      "\n",
      "    accuracy                           0.99      3000\n",
      "   macro avg       0.99      0.99      0.99      3000\n",
      "weighted avg       0.99      0.99      0.99      3000\n",
      "\n",
      "\n",
      "=== Random Forest Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    lung_aca       0.97      0.95      0.96      1000\n",
      "      lung_n       1.00      1.00      1.00      1000\n",
      "    lung_scc       0.95      0.97      0.96      1000\n",
      "\n",
      "    accuracy                           0.97      3000\n",
      "   macro avg       0.97      0.97      0.97      3000\n",
      "weighted avg       0.97      0.97      0.97      3000\n",
      "\n",
      "\n",
      "=== Logistic Regression Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    lung_aca       0.98      0.96      0.97      1000\n",
      "      lung_n       1.00      1.00      1.00      1000\n",
      "    lung_scc       0.96      0.98      0.97      1000\n",
      "\n",
      "    accuracy                           0.98      3000\n",
      "   macro avg       0.98      0.98      0.98      3000\n",
      "weighted avg       0.98      0.98      0.98      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Individual Classifier Results\n",
    "print(\"Individual Classifier Accuracies:\")\n",
    "knn_acc = accuracy_score(y_test, knn_pred)\n",
    "svm_acc = accuracy_score(y_test, svm_pred)\n",
    "rf_acc = accuracy_score(y_test, rf_pred)\n",
    "lr_acc = accuracy_score(y_test, lr_pred)\n",
    "\n",
    "print(f\"  KNN: {knn_acc:.4f}\")\n",
    "print(f\"  SVM: {svm_acc:.4f}\")\n",
    "print(f\"  RF : {rf_acc:.4f}\")\n",
    "print(f\"  LR : {lr_acc:.4f}\")\n",
    "\n",
    "# Display individual classification reports\n",
    "target_names = [id2label[i] for i in range(num_classes)]\n",
    "\n",
    "print(\"\\n=== KNN Classification Report ===\")\n",
    "print(classification_report(y_test, knn_pred, target_names=target_names))\n",
    "\n",
    "print(\"\\n=== SVM Classification Report ===\")\n",
    "print(classification_report(y_test, svm_pred, target_names=target_names))\n",
    "\n",
    "print(\"\\n=== Random Forest Classification Report ===\")\n",
    "print(classification_report(y_test, rf_pred, target_names=target_names))\n",
    "\n",
    "print(\"\\n=== Logistic Regression Classification Report ===\")\n",
    "print(classification_report(y_test, lr_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CORRECTED Priority-Based Ensemble Fusion (no XGBoost) ===\n",
      "Weighted-Average Ensemble Accuracy (labels): 0.9920\n",
      "Improvement over best individual: -0.0033\n"
     ]
    }
   ],
   "source": [
    "# CORRECTED: Priority-Based Weighting Implementation\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def calculate_priority_weights_fixed(accuracies):\n",
    "    \"\"\"Calculate priority weights from accuracies (descending rank).\"\"\"\n",
    "    ranked_indices = np.argsort(accuracies)[::-1]\n",
    "    ranked_accs = np.array([accuracies[i] for i in ranked_indices])\n",
    "    T = [1.0]\n",
    "    for j in range(1, len(ranked_accs)):\n",
    "        T.append(np.prod(ranked_accs[:j]))\n",
    "    T = np.array(T)\n",
    "    weights = T / np.sum(T)\n",
    "    return weights, ranked_indices\n",
    "\n",
    "def priority_weighted_prediction_fixed(predictions, weights, ranked_indices):\n",
    "    ranked_predictions = predictions[ranked_indices]\n",
    "    # For label predictions, use weighted voting\n",
    "    n_samples = ranked_predictions.shape[1]\n",
    "    n_clf = ranked_predictions.shape[0]\n",
    "    votes = {}\n",
    "    for i in range(n_samples):\n",
    "        counts = {}\n",
    "        for j in range(n_clf):\n",
    "            label = ranked_predictions[j, i]\n",
    "            counts[label] = counts.get(label, 0) + weights[j]\n",
    "        pred = max(counts.items(), key=lambda x: x[1])[0]\n",
    "        yield pred\n",
    "\n",
    "print(\"=== CORRECTED Priority-Based Ensemble Fusion (no XGBoost) ===\")\n",
    "\n",
    "all_predictions = np.array([knn_pred, svm_pred, rf_pred, lr_pred])\n",
    "all_accuracies = np.array([knn_acc, svm_acc, rf_acc, lr_acc])\n",
    "\n",
    "weights_fixed, ranked_indices = calculate_priority_weights_fixed(all_accuracies)\n",
    "weighted_pred_fixed_labels = np.fromiter(priority_weighted_prediction_fixed(all_predictions, weights_fixed, ranked_indices), dtype=int, count=len(y_test))\n",
    "\n",
    "weighted_ens_acc_fixed = accuracy_score(y_test, weighted_pred_fixed_labels)\n",
    "\n",
    "print(f\"Weighted-Average Ensemble Accuracy (labels): {weighted_ens_acc_fixed:.4f}\")\n",
    "print(f\"Improvement over best individual: {weighted_ens_acc_fixed - max(all_accuracies):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Individual Classifier Accuracies:\n",
      "  KNN: 0.9953\n",
      "  SVM: 0.9887\n",
      "  RF : 0.9733\n",
      "\n",
      "=== KNN Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    lung_aca       1.00      0.99      0.99      1000\n",
      "      lung_n       1.00      1.00      1.00      1000\n",
      "    lung_scc       0.99      1.00      0.99      1000\n",
      "\n",
      "    accuracy                           1.00      3000\n",
      "   macro avg       1.00      1.00      1.00      3000\n",
      "weighted avg       1.00      1.00      1.00      3000\n",
      "\n",
      "\n",
      "=== SVM Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    lung_aca       0.98      0.98      0.98      1000\n",
      "      lung_n       1.00      1.00      1.00      1000\n",
      "    lung_scc       0.98      0.98      0.98      1000\n",
      "\n",
      "    accuracy                           0.99      3000\n",
      "   macro avg       0.99      0.99      0.99      3000\n",
      "weighted avg       0.99      0.99      0.99      3000\n",
      "\n",
      "\n",
      "=== Random Forest Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    lung_aca       0.97      0.95      0.96      1000\n",
      "      lung_n       1.00      1.00      1.00      1000\n",
      "    lung_scc       0.95      0.97      0.96      1000\n",
      "\n",
      "    accuracy                           0.97      3000\n",
      "   macro avg       0.97      0.97      0.97      3000\n",
      "weighted avg       0.97      0.97      0.97      3000\n",
      "\n",
      "\n",
      "////////////////////////////////////////////////////////////\n",
      "\n",
      "Ensemble Accuracy (Weighted Priority): 0.9920\n",
      "\n",
      "Improvement over best individual: -0.0033\n",
      "\n",
      "=== Ensemble Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    lung_aca       0.99      0.98      0.99      1000\n",
      "      lung_n       1.00      1.00      1.00      1000\n",
      "    lung_scc       0.98      0.99      0.99      1000\n",
      "\n",
      "    accuracy                           0.99      3000\n",
      "   macro avg       0.99      0.99      0.99      3000\n",
      "weighted avg       0.99      0.99      0.99      3000\n",
      "\n",
      "\n",
      "////////////////////////////////////////////////////////////\n",
      "\n",
      "============================================================\n",
      "FINAL RESULTS SUMMARY\n",
      "============================================================\n",
      "Total samples processed: 15000\n",
      "Features selected by AGWO: 650 / 6400 (10.2%)\n",
      "Test set size: 3000\n",
      "\n",
      "Classifier Accuracies:\n",
      "  KNN:              0.9953\n",
      "  SVM:              0.9887\n",
      "  Random Forest:    0.9733\n",
      "  Logistic Reg:     0.9820\n",
      "  Ensemble (Fusion): 0.9920 ← BEST\n",
      "\n",
      "Class Labels:\n",
      "  0: lung_aca\n",
      "  1: lung_n\n",
      "  2: lung_scc\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Final Formatted Results Display\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Individual Classifier Accuracies:\")\n",
    "print(f\"  KNN: {knn_acc:.4f}\")\n",
    "print(f\"  SVM: {svm_acc:.4f}\")\n",
    "print(f\"  RF : {rf_acc:.4f}\")\n",
    "\n",
    "print(\"\\n=== KNN Classification Report ===\")\n",
    "print(classification_report(y_test, knn_pred, target_names=target_names))\n",
    "\n",
    "print(\"\\n=== SVM Classification Report ===\")\n",
    "print(classification_report(y_test, svm_pred, target_names=target_names))\n",
    "\n",
    "print(\"\\n=== Random Forest Classification Report ===\")\n",
    "print(classification_report(y_test, rf_pred, target_names=target_names))\n",
    "\n",
    "print(\"\\n\" + \"/\"*60)\n",
    "\n",
    "# Best ensemble result (use corrected weighted ensemble if available)\n",
    "if 'weighted_ens_acc_fixed' in globals():\n",
    "    best_ens_acc = weighted_ens_acc_fixed\n",
    "    best_ens_pred = weighted_pred_fixed_labels\n",
    "    ens_method = \"Weighted Priority\"\n",
    "elif 'weighted_ens_acc' in globals():\n",
    "    best_ens_acc = weighted_ens_acc\n",
    "    best_ens_pred = weighted_ensemble_pred\n",
    "    ens_method = \"Weighted Average\"\n",
    "else:\n",
    "    best_ens_acc = ens_acc\n",
    "    best_ens_pred = ens\n",
    "    ens_method = \"Priority-Based\"\n",
    "\n",
    "print(f\"\\nEnsemble Accuracy ({ens_method}): {best_ens_acc:.4f}\")\n",
    "\n",
    "best_individual = max(knn_acc, svm_acc, rf_acc, lr_acc)\n",
    "improvement = best_ens_acc - best_individual\n",
    "print(f\"\\nImprovement over best individual: {improvement:.4f}\")\n",
    "\n",
    "print(\"\\n=== Ensemble Classification Report ===\")\n",
    "print(classification_report(y_test, best_ens_pred, target_names=target_names))\n",
    "\n",
    "print(\"\\n\" + \"/\"*60)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL RESULTS SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total samples processed: {len(y_full)}\")\n",
    "\n",
    "# Feature selection info\n",
    "if 'selected_features' in globals():\n",
    "    sel_count = len(selected_features)\n",
    "    orig_count = X_tr.shape[1] if 'X_tr' in globals() else X_full.shape[1]\n",
    "    print(f\"Features selected by AGWO: {sel_count} / {orig_count} ({sel_count/orig_count:.1%})\")\n",
    "\n",
    "print(f\"Test set size: {len(y_test)}\")\n",
    "\n",
    "print(\"\\nClassifier Accuracies:\")\n",
    "print(f\"  KNN:              {knn_acc:.4f}\")\n",
    "print(f\"  SVM:              {svm_acc:.4f}\")\n",
    "print(f\"  Random Forest:    {rf_acc:.4f}\")\n",
    "print(f\"  Logistic Reg:     {lr_acc:.4f}\")\n",
    "print(f\"  Ensemble (Fusion): {best_ens_acc:.4f} ← BEST\")\n",
    "\n",
    "print(\"\\nClass Labels:\")\n",
    "for i, label in id2label.items():\n",
    "    print(f\"  {i}: {label}\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

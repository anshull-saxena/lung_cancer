{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lung Histopathology Classification: ACA / N / SCC\n",
    "## Multi-CNN + Channel Attention + GA + KNN/SVM/RF + Fusion\n",
    "\n",
    "This notebook implements a comprehensive lung histopathology classification system that combines:\n",
    "- Multiple CNN backbones (DenseNet121, ResNet50, VGG16)\n",
    "- Channel attention mechanism (SE blocks)\n",
    "- Genetic Algorithm for feature selection\n",
    "- Ensemble of classical ML classifiers (KNN, SVM, Random Forest)\n",
    "- Majority voting fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy==1.26.4 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from -r requirements.txt (line 1)) (1.26.4)\n",
      "Requirement already satisfied: pandas in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from -r requirements.txt (line 2)) (2.1.4)\n",
      "Requirement already satisfied: scipy in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from -r requirements.txt (line 3)) (1.11.4)\n",
      "Collecting tensorflow==2.16.1 (from -r requirements.txt (line 4))\n",
      "  Using cached tensorflow-2.16.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: scikit-learn in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from -r requirements.txt (line 5)) (1.3.2)\n",
      "Requirement already satisfied: deap in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from -r requirements.txt (line 6)) (1.4.3)\n",
      "Requirement already satisfied: Pillow in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from -r requirements.txt (line 7)) (12.0.0)\n",
      "Requirement already satisfied: jupyter in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from -r requirements.txt (line 8)) (1.1.1)\n",
      "Requirement already satisfied: ipykernel in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from -r requirements.txt (line 9)) (6.26.0)\n",
      "Requirement already satisfied: kagglehub in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from -r requirements.txt (line 10)) (0.3.13)\n",
      "Requirement already satisfied: tqdm in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from -r requirements.txt (line 11)) (4.67.1)\n",
      "Requirement already satisfied: matplotlib in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from -r requirements.txt (line 12)) (3.8.2)\n",
      "Requirement already satisfied: seaborn in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from -r requirements.txt (line 13)) (0.13.2)\n",
      "Requirement already satisfied: psutil in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from -r requirements.txt (line 14)) (7.1.1)\n",
      "Requirement already satisfied: setuptools in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from -r requirements.txt (line 15)) (80.9.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow==2.16.1->-r requirements.txt (line 4)) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow==2.16.1->-r requirements.txt (line 4)) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow==2.16.1->-r requirements.txt (line 4)) (25.9.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow==2.16.1->-r requirements.txt (line 4)) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow==2.16.1->-r requirements.txt (line 4)) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow==2.16.1->-r requirements.txt (line 4)) (3.15.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow==2.16.1->-r requirements.txt (line 4)) (18.1.1)\n",
      "Collecting ml-dtypes~=0.3.1 (from tensorflow==2.16.1->-r requirements.txt (line 4))\n",
      "  Using cached ml_dtypes-0.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow==2.16.1->-r requirements.txt (line 4)) (3.4.0)\n",
      "Requirement already satisfied: packaging in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow==2.16.1->-r requirements.txt (line 4)) (25.0)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow==2.16.1->-r requirements.txt (line 4))\n",
      "  Using cached protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow==2.16.1->-r requirements.txt (line 4)) (2.32.5)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow==2.16.1->-r requirements.txt (line 4)) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow==2.16.1->-r requirements.txt (line 4)) (3.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow==2.16.1->-r requirements.txt (line 4)) (4.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow==2.16.1->-r requirements.txt (line 4)) (2.0.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow==2.16.1->-r requirements.txt (line 4)) (1.76.0)\n",
      "Collecting tensorboard<2.17,>=2.16 (from tensorflow==2.16.1->-r requirements.txt (line 4))\n",
      "  Using cached tensorboard-2.16.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: keras>=3.0.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow==2.16.1->-r requirements.txt (line 4)) (3.12.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.1->-r requirements.txt (line 4)) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.1->-r requirements.txt (line 4)) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.1->-r requirements.txt (line 4)) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.1->-r requirements.txt (line 4)) (2025.10.5)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.1->-r requirements.txt (line 4)) (3.9)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.1->-r requirements.txt (line 4)) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.1->-r requirements.txt (line 4)) (3.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from pandas->-r requirements.txt (line 2)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from pandas->-r requirements.txt (line 2)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from pandas->-r requirements.txt (line 2)) (2025.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from scikit-learn->-r requirements.txt (line 5)) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from scikit-learn->-r requirements.txt (line 5)) (3.6.0)\n",
      "Requirement already satisfied: notebook in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from jupyter->-r requirements.txt (line 8)) (7.4.7)\n",
      "Requirement already satisfied: jupyter-console in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from jupyter->-r requirements.txt (line 8)) (6.6.3)\n",
      "Requirement already satisfied: nbconvert in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from jupyter->-r requirements.txt (line 8)) (7.16.6)\n",
      "Requirement already satisfied: ipywidgets in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from jupyter->-r requirements.txt (line 8)) (8.1.1)\n",
      "Requirement already satisfied: jupyterlab in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from jupyter->-r requirements.txt (line 8)) (4.4.10)\n",
      "Requirement already satisfied: comm>=0.1.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from ipykernel->-r requirements.txt (line 9)) (0.2.3)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from ipykernel->-r requirements.txt (line 9)) (1.8.17)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from ipykernel->-r requirements.txt (line 9)) (8.17.2)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from ipykernel->-r requirements.txt (line 9)) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from ipykernel->-r requirements.txt (line 9)) (5.9.1)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from ipykernel->-r requirements.txt (line 9)) (0.2.1)\n",
      "Requirement already satisfied: nest-asyncio in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from ipykernel->-r requirements.txt (line 9)) (1.6.0)\n",
      "Requirement already satisfied: pyzmq>=20 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from ipykernel->-r requirements.txt (line 9)) (27.1.0)\n",
      "Requirement already satisfied: tornado>=6.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from ipykernel->-r requirements.txt (line 9)) (6.5.2)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from ipykernel->-r requirements.txt (line 9)) (5.14.3)\n",
      "Requirement already satisfied: pyyaml in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from kagglehub->-r requirements.txt (line 10)) (6.0.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 12)) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 12)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 12)) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 12)) (1.4.9)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 12)) (3.2.5)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow==2.16.1->-r requirements.txt (line 4)) (0.45.1)\n",
      "Requirement already satisfied: decorator in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 9)) (5.2.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 9)) (0.19.2)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 9)) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 9)) (2.19.2)\n",
      "Requirement already satisfied: stack-data in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 9)) (0.6.3)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 9)) (4.9.0)\n",
      "Requirement already satisfied: wcwidth in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=7.23.1->ipykernel->-r requirements.txt (line 9)) (0.2.14)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->-r requirements.txt (line 9)) (0.8.5)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->-r requirements.txt (line 9)) (4.5.0)\n",
      "Requirement already satisfied: rich in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from keras>=3.0.0->tensorflow==2.16.1->-r requirements.txt (line 4)) (14.2.0)\n",
      "Requirement already satisfied: namex in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from keras>=3.0.0->tensorflow==2.16.1->-r requirements.txt (line 4)) (0.1.0)\n",
      "Requirement already satisfied: optree in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from keras>=3.0.0->tensorflow==2.16.1->-r requirements.txt (line 4)) (0.17.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel->-r requirements.txt (line 9)) (0.7.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow==2.16.1->-r requirements.txt (line 4)) (3.0.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.9 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from ipywidgets->jupyter->-r requirements.txt (line 8)) (4.0.14)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.9 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from ipywidgets->jupyter->-r requirements.txt (line 8)) (3.0.15)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from jupyterlab->jupyter->-r requirements.txt (line 8)) (2.0.5)\n",
      "Requirement already satisfied: httpx<1,>=0.25.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from jupyterlab->jupyter->-r requirements.txt (line 8)) (0.28.1)\n",
      "Requirement already satisfied: jinja2>=3.0.3 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from jupyterlab->jupyter->-r requirements.txt (line 8)) (3.1.6)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from jupyterlab->jupyter->-r requirements.txt (line 8)) (2.3.0)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from jupyterlab->jupyter->-r requirements.txt (line 8)) (2.17.0)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from jupyterlab->jupyter->-r requirements.txt (line 8)) (2.28.0)\n",
      "Requirement already satisfied: notebook-shim>=0.2 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from jupyterlab->jupyter->-r requirements.txt (line 8)) (0.2.4)\n",
      "Requirement already satisfied: anyio in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter->-r requirements.txt (line 8)) (4.11.0)\n",
      "Requirement already satisfied: httpcore==1.* in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter->-r requirements.txt (line 8)) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.25.0->jupyterlab->jupyter->-r requirements.txt (line 8)) (0.16.0)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 8)) (25.1.0)\n",
      "Requirement already satisfied: jupyter-events>=0.11.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 8)) (0.12.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 8)) (0.5.3)\n",
      "Requirement already satisfied: nbformat>=5.3.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 8)) (5.10.4)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 8)) (0.23.1)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 8)) (1.8.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 8)) (0.18.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 8)) (1.9.0)\n",
      "Requirement already satisfied: babel>=2.10 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->-r requirements.txt (line 8)) (2.17.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->-r requirements.txt (line 8)) (0.12.1)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->-r requirements.txt (line 8)) (4.25.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from anyio->httpx<1,>=0.25.0->jupyterlab->jupyter->-r requirements.txt (line 8)) (1.3.1)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 8)) (25.1.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->-r requirements.txt (line 8)) (25.4.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->-r requirements.txt (line 8)) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->-r requirements.txt (line 8)) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->-r requirements.txt (line 8)) (0.28.0)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 8)) (4.0.0)\n",
      "Requirement already satisfied: rfc3339-validator in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 8)) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 8)) (0.1.1)\n",
      "Requirement already satisfied: fqdn in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 8)) (1.5.1)\n",
      "Requirement already satisfied: isoduration in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 8)) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 8)) (3.0.0)\n",
      "Requirement already satisfied: rfc3987-syntax>=1.1.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 8)) (1.1.0)\n",
      "Requirement already satisfied: uri-template in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 8)) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 8)) (24.11.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from nbconvert->jupyter->-r requirements.txt (line 8)) (4.14.2)\n",
      "Requirement already satisfied: bleach!=5.0.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from bleach[css]!=5.0.0->nbconvert->jupyter->-r requirements.txt (line 8)) (6.2.0)\n",
      "Requirement already satisfied: defusedxml in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from nbconvert->jupyter->-r requirements.txt (line 8)) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from nbconvert->jupyter->-r requirements.txt (line 8)) (0.3.0)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from nbconvert->jupyter->-r requirements.txt (line 8)) (3.1.4)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from nbconvert->jupyter->-r requirements.txt (line 8)) (0.10.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from nbconvert->jupyter->-r requirements.txt (line 8)) (1.5.1)\n",
      "Requirement already satisfied: webencodings in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->jupyter->-r requirements.txt (line 8)) (0.5.1)\n",
      "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from bleach[css]!=5.0.0->nbconvert->jupyter->-r requirements.txt (line 8)) (1.4.0)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 8)) (2.21.2)\n",
      "Requirement already satisfied: lark>=1.2.2 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 8)) (1.3.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 8)) (2.0.0)\n",
      "Requirement already satisfied: pycparser in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 8)) (2.23)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from beautifulsoup4->nbconvert->jupyter->-r requirements.txt (line 8)) (2.8)\n",
      "Requirement already satisfied: arrow>=0.15.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r requirements.txt (line 8)) (1.4.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from rich->keras>=3.0.0->tensorflow==2.16.1->-r requirements.txt (line 4)) (4.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow==2.16.1->-r requirements.txt (line 4)) (0.1.2)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from stack-data->ipython>=7.23.1->ipykernel->-r requirements.txt (line 9)) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from stack-data->ipython>=7.23.1->ipykernel->-r requirements.txt (line 9)) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from stack-data->ipython>=7.23.1->ipykernel->-r requirements.txt (line 9)) (0.2.3)\n",
      "Using cached tensorflow-2.16.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (589.9 MB)\n",
      "Using cached ml_dtypes-0.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "Using cached protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "Using cached tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
      "Installing collected packages: protobuf, ml-dtypes, tensorboard, tensorflow\n",
      "\u001b[2K  Attempting uninstall: protobuf\n",
      "\u001b[2K    Found existing installation: protobuf 6.33.0\n",
      "\u001b[2K    Uninstalling protobuf-6.33.0:\n",
      "\u001b[2K      Successfully uninstalled protobuf-6.33.0\n",
      "\u001b[2K  Attempting uninstall: ml-dtypes\n",
      "\u001b[2K    Found existing installation: ml_dtypes 0.5.3\n",
      "\u001b[2K    Uninstalling ml_dtypes-0.5.3:\n",
      "\u001b[2K      Successfully uninstalled ml_dtypes-0.5.3\n",
      "\u001b[2K  Attempting uninstall: tensorboard0m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [ml-dtypes]\n",
      "\u001b[2K    Found existing installation: tensorboard 2.20.0━━━━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [ml-dtypes]\n",
      "\u001b[2K    Uninstalling tensorboard-2.20.0:━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [ml-dtypes]\n",
      "\u001b[2K      Successfully uninstalled tensorboard-2.20.0━━━━━━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [ml-dtypes]\n",
      "\u001b[2K  Attempting uninstall: tensorflow90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/4\u001b[0m [tensorboard]\n",
      "\u001b[2K    Found existing installation: tensorflow 2.20.00m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m3/4\u001b[0m [tensorflow]\n",
      "\u001b[2K    Uninstalling tensorflow-2.20.0:━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m3/4\u001b[0m [tensorflow]\n",
      "\u001b[2K      Successfully uninstalled tensorflow-2.20.0\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m3/4\u001b[0m [tensorflow]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [tensorflow]4\u001b[0m [tensorflow]\n",
      "\u001b[1A\u001b[2KSuccessfully installed ml-dtypes-0.3.2 protobuf-4.25.8 tensorboard-2.16.2 tensorflow-2.16.1\n"
     ]
    }
   ],
   "source": [
    "# Package installation (commented out to avoid build errors)\n",
    "# Use conda environment or pre-installed packages instead\n",
    "!pip install -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import os, random, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.applications import DenseNet121, ResNet50, EfficientNetB0, InceptionV3\n",
    "from tensorflow.keras.applications.densenet import preprocess_input as pre_densenet\n",
    "from tensorflow.keras.applications.resnet import preprocess_input as pre_resnet\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input as pre_efficientnet\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input as pre_inception\n",
    "from tensorflow.keras.layers import (Input, GlobalAveragePooling2D, GlobalMaxPooling2D,\n",
    "                                     Concatenate, Dense, Reshape, Multiply, Lambda)\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from scipy.stats import mode\n",
    "\n",
    "# from deap import base, creator, tools  # GA removed, not needed\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow[and-cuda] in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (2.16.1)\n",
      "Collecting tensorflow[and-cuda]\n",
      "  Using cached tensorflow-2.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow[and-cuda]) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow[and-cuda]) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow[and-cuda]) (25.9.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow[and-cuda]) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow[and-cuda]) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow[and-cuda]) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow[and-cuda]) (3.4.0)\n",
      "Requirement already satisfied: packaging in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow[and-cuda]) (25.0)\n",
      "Collecting protobuf>=5.28.0 (from tensorflow[and-cuda])\n",
      "  Using cached protobuf-6.33.0-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow[and-cuda]) (2.32.5)\n",
      "Requirement already satisfied: setuptools in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow[and-cuda]) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow[and-cuda]) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow[and-cuda]) (3.2.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow[and-cuda]) (4.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow[and-cuda]) (2.0.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow[and-cuda]) (1.76.0)\n",
      "Collecting tensorboard~=2.20.0 (from tensorflow[and-cuda])\n",
      "  Using cached tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: keras>=3.10.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow[and-cuda]) (3.12.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow[and-cuda]) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow[and-cuda]) (3.15.1)\n",
      "Collecting ml_dtypes<1.0.0,>=0.5.1 (from tensorflow[and-cuda])\n",
      "  Using cached ml_dtypes-0.5.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
      "Requirement already satisfied: nvidia-cublas-cu12<13.0,>=12.5.3.2 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow[and-cuda]) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12<13.0,>=12.5.82 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow[and-cuda]) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-nvcc-cu12<13.0,>=12.5.82 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow[and-cuda]) (12.9.86)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12<13.0,>=12.5.82 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow[and-cuda]) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12<13.0,>=12.5.82 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow[and-cuda]) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12<10.0,>=9.3.0.75 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow[and-cuda]) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cufft-cu12<12.0,>=11.2.3.61 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow[and-cuda]) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12<11.0,>=10.3.6.82 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow[and-cuda]) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12<12.0,>=11.6.3.83 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow[and-cuda]) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12<13.0,>=12.5.1.3 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow[and-cuda]) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-nccl-cu12<3.0,>=2.25.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow[and-cuda]) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12<13.0,>=12.5.82 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow[and-cuda]) (12.8.93)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow[and-cuda]) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow[and-cuda]) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow[and-cuda]) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow[and-cuda]) (2025.10.5)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow[and-cuda]) (3.9)\n",
      "Requirement already satisfied: pillow in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow[and-cuda]) (12.0.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow[and-cuda]) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow[and-cuda]) (3.1.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow[and-cuda]) (0.45.1)\n",
      "Requirement already satisfied: rich in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from keras>=3.10.0->tensorflow[and-cuda]) (14.2.0)\n",
      "Requirement already satisfied: namex in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from keras>=3.10.0->tensorflow[and-cuda]) (0.1.0)\n",
      "Requirement already satisfied: optree in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from keras>=3.10.0->tensorflow[and-cuda]) (0.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow[and-cuda]) (3.0.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from rich->keras>=3.10.0->tensorflow[and-cuda]) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from rich->keras>=3.10.0->tensorflow[and-cuda]) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow[and-cuda]) (0.1.2)\n",
      "Using cached tensorflow-2.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (620.7 MB)\n",
      "^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -U \"tensorflow[and-cuda]\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "🔍 GPU DETECTION & AUTO-CONFIGURATION\n",
      "============================================================\n",
      "❌ No GPU detected — attempting auto-fix...\n",
      "⚙️ Installing missing package: tensorflow[and-cuda] ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow[and-cuda] in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (2.16.1)\n",
      "Collecting tensorflow[and-cuda]\n",
      "  Using cached tensorflow-2.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow[and-cuda]) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow[and-cuda]) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow[and-cuda]) (25.9.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow[and-cuda]) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow[and-cuda]) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow[and-cuda]) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow[and-cuda]) (3.4.0)\n",
      "Requirement already satisfied: packaging in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow[and-cuda]) (25.0)\n",
      "Collecting protobuf>=5.28.0 (from tensorflow[and-cuda])\n",
      "  Using cached protobuf-6.33.0-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow[and-cuda]) (2.32.5)\n",
      "Requirement already satisfied: setuptools in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow[and-cuda]) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow[and-cuda]) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow[and-cuda]) (3.2.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow[and-cuda]) (4.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow[and-cuda]) (2.0.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow[and-cuda]) (1.76.0)\n",
      "Collecting tensorboard~=2.20.0 (from tensorflow[and-cuda])\n",
      "  Using cached tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: keras>=3.10.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow[and-cuda]) (3.12.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow[and-cuda]) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow[and-cuda]) (3.15.1)\n",
      "Collecting ml_dtypes<1.0.0,>=0.5.1 (from tensorflow[and-cuda])\n",
      "  Using cached ml_dtypes-0.5.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
      "Requirement already satisfied: nvidia-cublas-cu12<13.0,>=12.5.3.2 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow[and-cuda]) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12<13.0,>=12.5.82 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow[and-cuda]) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-nvcc-cu12<13.0,>=12.5.82 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow[and-cuda]) (12.9.86)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12<13.0,>=12.5.82 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow[and-cuda]) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12<13.0,>=12.5.82 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow[and-cuda]) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12<10.0,>=9.3.0.75 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow[and-cuda]) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cufft-cu12<12.0,>=11.2.3.61 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow[and-cuda]) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12<11.0,>=10.3.6.82 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow[and-cuda]) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12<12.0,>=11.6.3.83 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow[and-cuda]) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12<13.0,>=12.5.1.3 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow[and-cuda]) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-nccl-cu12<3.0,>=2.25.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow[and-cuda]) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12<13.0,>=12.5.82 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorflow[and-cuda]) (12.8.93)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow[and-cuda]) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow[and-cuda]) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow[and-cuda]) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow[and-cuda]) (2025.10.5)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow[and-cuda]) (3.9)\n",
      "Requirement already satisfied: pillow in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow[and-cuda]) (12.0.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow[and-cuda]) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow[and-cuda]) (3.1.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow[and-cuda]) (0.45.1)\n",
      "Requirement already satisfied: rich in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from keras>=3.10.0->tensorflow[and-cuda]) (14.2.0)\n",
      "Requirement already satisfied: namex in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from keras>=3.10.0->tensorflow[and-cuda]) (0.1.0)\n",
      "Requirement already satisfied: optree in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from keras>=3.10.0->tensorflow[and-cuda]) (0.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow[and-cuda]) (3.0.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from rich->keras>=3.10.0->tensorflow[and-cuda]) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from rich->keras>=3.10.0->tensorflow[and-cuda]) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow[and-cuda]) (0.1.2)\n",
      "Using cached tensorflow-2.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (620.7 MB)\n",
      "Using cached ml_dtypes-0.5.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (4.9 MB)\n",
      "Using cached tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
      "Using cached protobuf-6.33.0-cp39-abi3-manylinux2014_x86_64.whl (323 kB)\n",
      "Installing collected packages: protobuf, ml_dtypes, tensorboard, tensorflow\n",
      "\u001b[2K  Attempting uninstall: protobuf\n",
      "\u001b[2K    Found existing installation: protobuf 4.25.8\n",
      "\u001b[2K    Uninstalling protobuf-4.25.8:\n",
      "\u001b[2K      Successfully uninstalled protobuf-4.25.8\n",
      "\u001b[2K  Attempting uninstall: ml_dtypes━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0/4\u001b[0m [protobuf]\n",
      "\u001b[2K    Found existing installation: ml-dtypes 0.3.2 \u001b[32m0/4\u001b[0m [protobuf]\n",
      "\u001b[2K    Uninstalling ml-dtypes-0.3.2:━━━━━━━━━━━\u001b[0m \u001b[32m0/4\u001b[0m [protobuf]\n",
      "\u001b[2K      Successfully uninstalled ml-dtypes-0.3.20m \u001b[32m0/4\u001b[0m [protobuf]\n",
      "\u001b[2K  Attempting uninstall: tensorboard━━━━━━━━━\u001b[0m \u001b[32m0/4\u001b[0m [protobuf]\n",
      "\u001b[2K    Found existing installation: tensorboard 2.16.232m0/4\u001b[0m [protobuf]\n",
      "\u001b[2K    Uninstalling tensorboard-2.16.2:m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/4\u001b[0m [tensorboard]\n",
      "\u001b[2K      Successfully uninstalled tensorboard-2.16.2━━━━━━━━━━━━━\u001b[0m \u001b[32m2/4\u001b[0m [tensorboard]\n",
      "\u001b[2K  Attempting uninstall: tensorflow90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/4\u001b[0m [tensorboard]\n",
      "\u001b[2K    Found existing installation: tensorflow 2.16.1━━━━━━━━━━━━\u001b[0m \u001b[32m2/4\u001b[0m [tensorboard]\n",
      "\u001b[2K    Uninstalling tensorflow-2.16.1:━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m3/4\u001b[0m [tensorflow]\n",
      "\u001b[2K      Successfully uninstalled tensorflow-2.16.1\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m3/4\u001b[0m [tensorflow]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [tensorflow]4\u001b[0m [tensorflow]\n",
      "\u001b[1A\u001b[2KSuccessfully installed ml_dtypes-0.5.3 protobuf-6.33.0 tensorboard-2.20.0 tensorflow-2.20.0\n",
      "✅ tensorflow[and-cuda] installed successfully. Restarting TF runtime...\n",
      "❌ Auto-fix failed: cannot import name 'check_pinned' from 'tensorflow.python.ops.gen_experimental_dataset_ops' (/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/tensorflow/python/ops/gen_experimental_dataset_ops.py)\n",
      "\n",
      "TensorFlow version: 2.16.1\n",
      "Built with CUDA: True\n",
      "\n",
      "⚠️ GPU still not detected. Falling back to CPU.\n",
      "   Please verify your NVIDIA driver & CUDA runtime manually:\n",
      "   https://www.tensorflow.org/install/gpu\n",
      "\n",
      "🎯 Default device: CPU\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import tensorflow as tf\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"🔍 GPU DETECTION & AUTO-CONFIGURATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check if GPU runtime is already available\n",
    "def has_gpu():\n",
    "    return bool(tf.config.list_physical_devices(\"GPU\"))\n",
    "\n",
    "# Helper: install pip package silently\n",
    "def install_package(pkg):\n",
    "    print(f\"⚙️ Installing missing package: {pkg} ...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-U\", pkg])\n",
    "\n",
    "# Step 1: Ensure tensorflow[and-cuda] is installed if no GPU libs found\n",
    "if not has_gpu():\n",
    "    try:\n",
    "        print(\"❌ No GPU detected — attempting auto-fix...\")\n",
    "        install_package(\"tensorflow[and-cuda]\")\n",
    "        print(\"✅ tensorflow[and-cuda] installed successfully. Restarting TF runtime...\")\n",
    "        import importlib\n",
    "        importlib.reload(tf)\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Auto-fix failed: {e}\")\n",
    "\n",
    "# Step 2: Recheck GPU status\n",
    "gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "print(f\"\\nTensorFlow version: {tf.__version__}\")\n",
    "print(f\"Built with CUDA: {tf.test.is_built_with_cuda()}\")\n",
    "\n",
    "if gpus:\n",
    "    print(f\"\\n✅ {len(gpus)} GPU(s) detected:\")\n",
    "    for i, gpu in enumerate(gpus):\n",
    "        print(f\"  GPU {i}: {gpu.name}\")\n",
    "\n",
    "    # Enable memory growth to avoid full VRAM allocation\n",
    "    for gpu in gpus:\n",
    "        try:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        except RuntimeError:\n",
    "            pass\n",
    "\n",
    "    print(\"✅ GPU memory growth enabled\")\n",
    "\n",
    "    # Test computation\n",
    "    with tf.device(\"/GPU:0\"):\n",
    "        a = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
    "        b = tf.matmul(a, a)\n",
    "        print(f\"✅ GPU test computation successful →\\n{b.numpy()}\")\n",
    "\n",
    "else:\n",
    "    print(\"\\n⚠️ GPU still not detected. Falling back to CPU.\")\n",
    "    print(\"   Please verify your NVIDIA driver & CUDA runtime manually:\")\n",
    "    print(\"   https://www.tensorflow.org/install/gpu\")\n",
    "\n",
    "# Step 3: Default device info\n",
    "logical_gpus = tf.config.list_logical_devices(\"GPU\")\n",
    "default_device = logical_gpus[0].name if logical_gpus else \"CPU\"\n",
    "print(f\"\\n🎯 Default device: {default_device}\")\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration and Data Setup - OPTIMIZED FOR L4 GPU\n",
    "DATA_DIR   = \"/teamspace/studios/this_studio/lung_cancer/dataset/lung_image_sets\"  # << set this\n",
    "IMG_SIZE   = (224, 224)\n",
    "BATCH_SIZE = 64  # OPTIMIZED: Increased from 24 for L4 GPU (16GB VRAM)\n",
    "SEED       = 42\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# OPTIMIZATION: Enable mixed precision for 2-3x speedup on L4\n",
    "from tensorflow.keras import mixed_precision\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_global_policy(policy)\n",
    "print('✅ Mixed precision enabled (float16 compute, float32 variables)')\n",
    "\n",
    "# OPTIMIZATION: Configure GPU for maximum performance\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f'✅ GPU memory growth enabled for {len(gpus)} GPU(s)')\n",
    "    except RuntimeError as e:\n",
    "        print(f'GPU config warning: {e}')\n",
    "\n",
    "print(f\"Configuration set:\")\n",
    "print(f\"Data Directory: {DATA_DIR}\")\n",
    "print(f\"Image Size: {IMG_SIZE}\")\n",
    "print(f\"Batch Size: {BATCH_SIZE} (optimized for L4)\")\n",
    "print(f\"Random Seed: {SEED}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of attention heads for multi-head channel attention\n",
    "NUM_ATTENTION_HEADS = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    validation_split=0.20,\n",
    "    rotation_range=20,\n",
    "    horizontal_flip=True,\n",
    "    # IMPORTANT: no rescale here, since we feed raw to model-specific preprocessors\n",
    ")\n",
    "\n",
    "def make_gen(subset):\n",
    "    return train_datagen.flow_from_directory(\n",
    "        DATA_DIR,\n",
    "        target_size=IMG_SIZE,\n",
    "        class_mode='categorical',\n",
    "        batch_size=BATCH_SIZE,\n",
    "        subset=subset,\n",
    "        seed=SEED,\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "train_gen = make_gen('training')\n",
    "val_gen   = make_gen('validation')\n",
    "num_classes = train_gen.num_classes\n",
    "class_indices = train_gen.class_indices\n",
    "id2label = {v:k for k,v in class_indices.items()}\n",
    "\n",
    "print(\"Classes:\", class_indices)\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "print(f\"Training samples: {train_gen.samples}\")\n",
    "print(f\"Validation samples: {val_gen.samples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Channel Attention (Multi-Headed) Implementation - GPU OPTIMIZED\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer, Dense\n",
    "\n",
    "# GPU Configuration - Run this first!\n",
    "print(\"=\" * 60)\n",
    "print(\"GPU CONFIGURATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Enable memory growth to prevent OOM errors\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"✓ {len(gpus)} GPU(s) detected and configured\")\n",
    "        print(f\"  Devices: {[gpu.name for gpu in gpus]}\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"✗ GPU configuration error: {e}\")\n",
    "else:\n",
    "    print(\"✗ No GPU detected - will use CPU\")\n",
    "    print(\"  Install: pip install tensorflow[and-cuda]\")\n",
    "\n",
    "print(f\"\\nTensorFlow: {tf.__version__}\")\n",
    "print(f\"CUDA support: {tf.test.is_built_with_cuda()}\")\n",
    "print(\"=\" * 60 + \"\\n\")\n",
    "\n",
    "\n",
    "class MultiHeadChannelAttention(Layer):\n",
    "    def __init__(self, num_heads=4, reduction=16, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_heads = num_heads\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.channel = input_shape[-1]\n",
    "        reduced_channels = max(self.channel // self.reduction, 1)\n",
    "        \n",
    "        # Batched dense layers for parallel processing (GPU-friendly)\n",
    "        self.dense1 = Dense(\n",
    "            self.num_heads * reduced_channels,\n",
    "            activation='relu',\n",
    "            name=f'{self.name}_d1'\n",
    "        )\n",
    "        self.dense2 = Dense(\n",
    "            self.num_heads * self.channel,\n",
    "            name=f'{self.name}_d2'\n",
    "        )\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        batch_size = tf.shape(x)[0]\n",
    "        \n",
    "        # Global pooling\n",
    "        gap = tf.reduce_mean(x, axis=[1,2])  # (batch, channels)\n",
    "        gmp = tf.reduce_max(x, axis=[1,2])   # (batch, channels)\n",
    "        \n",
    "        # Process all heads in parallel (GPU accelerated)\n",
    "        gap_feat = self.dense1(gap)  # (batch, num_heads * reduced)\n",
    "        gmp_feat = self.dense1(gmp)\n",
    "        \n",
    "        gap_attn = self.dense2(gap_feat)  # (batch, num_heads * channels)\n",
    "        gmp_attn = self.dense2(gmp_feat)\n",
    "        \n",
    "        # Reshape to separate heads: (batch, num_heads, channels)\n",
    "        combined = tf.reshape(\n",
    "            gap_attn + gmp_attn, \n",
    "            [batch_size, self.num_heads, self.channel]\n",
    "        )\n",
    "        \n",
    "        # Average across heads and apply sigmoid\n",
    "        attention = tf.nn.sigmoid(tf.reduce_mean(combined, axis=1))\n",
    "        \n",
    "        # Reshape for broadcasting: (batch, 1, 1, channels)\n",
    "        attention = tf.reshape(attention, [batch_size, 1, 1, self.channel])\n",
    "        \n",
    "        # Apply attention\n",
    "        return x * attention\n",
    "\n",
    "\n",
    "def multi_head_attention_block(x, reduction=16, name=None):\n",
    "    \"\"\"Multi-Headed Channel Attention block - GPU accelerated\"\"\"\n",
    "    NUM_ATTENTION_HEADS = 4  # Define this or pass as parameter\n",
    "    attn = MultiHeadChannelAttention(\n",
    "        num_heads=NUM_ATTENTION_HEADS, \n",
    "        reduction=reduction, \n",
    "        name=name\n",
    "    )(x)\n",
    "    return attn\n",
    "\n",
    "print(\"✓ Multi-head attention block ready (GPU-optimized)!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Lane function with GPU-accelerated backbones\n",
    "from tensorflow.keras.layers import Lambda, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications import ResNet50, DenseNet121, EfficientNetB0, InceptionV3\n",
    "\n",
    "def lane(tensor, backbone=\"resnet\", reduction=16):\n",
    "    \"\"\"Create a processing lane for each CNN backbone with multi-head channel attention (GPU-optimized)\"\"\"\n",
    "    if backbone == \"resnet\":\n",
    "        x = Lambda(pre_resnet, name=\"pre_resnet\")(tensor)\n",
    "        x = ResNet50(include_top=False, weights='imagenet')(x)\n",
    "    elif backbone == \"densenet\":\n",
    "        x = Lambda(pre_densenet, name=\"pre_densenet\")(tensor)\n",
    "        x = DenseNet121(include_top=False, weights='imagenet')(x)\n",
    "    elif backbone == \"efficientnet\":\n",
    "        x = Lambda(pre_efficientnet, name=\"pre_efficientnet\")(tensor)\n",
    "        x = EfficientNetB0(include_top=False, weights='imagenet')(x)\n",
    "    elif backbone == \"inception\":\n",
    "        x = Lambda(pre_inception, name=\"pre_inception\")(tensor)\n",
    "        x = InceptionV3(include_top=False, weights='imagenet')(x)\n",
    "    else:\n",
    "        raise ValueError(f'Unknown backbone: {backbone}')\n",
    "    \n",
    "    # Add multi-head channel attention (GPU-accelerated)\n",
    "    x = multi_head_attention_block(x, reduction=reduction, name=f\"mhca_{backbone}\")\n",
    "    \n",
    "    # Global Average Pooling to convert feature maps → vector\n",
    "    x = GlobalAveragePooling2D(name=f\"gap_{backbone}\")(x)\n",
    "    return x\n",
    "\n",
    "print(\"✓ Lane function ready with GPU-optimized multi-head attention!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Feature Extractor Model\n",
    "print(\"Building multi-backbone feature concatenator with multi-head attention...\")\n",
    "\n",
    "# Define input tensor with image size (224x224x3 RGB)\n",
    "inp = Input(shape=(224,224,3))\n",
    "\n",
    "# Extract features from DenseNet lane (multi-head attention)\n",
    "feat_d = lane(inp, \"densenet\", reduction=16)\n",
    "# Extract features from ResNet lane (multi-head attention)\n",
    "feat_r = lane(inp, \"resnet\", reduction=16)\n",
    "# Extract features from EfficientNetB0 lane (multi-head attention)\n",
    "feat_e = lane(inp, \"efficientnet\", reduction=16)\n",
    "# Extract features from InceptionV3 lane (multi-head attention)\n",
    "feat_i = lane(inp, \"inception\", reduction=16)\n",
    "\n",
    "# Concatenate features from all four backbones\n",
    "concat_feat = Concatenate(name=\"concat_feats\")([feat_d, feat_r, feat_e, feat_i])\n",
    "\n",
    "# Create feature extractor model (input → concatenated features)\n",
    "feature_model = Model(inp, concat_feat)\n",
    "\n",
    "# Get final concatenated feature dimension\n",
    "feature_dim = feature_model.output_shape[-1]\n",
    "\n",
    "print(f\"Feature extractor built successfully!\")\n",
    "print(f\"Feature dimension: {feature_dim}\")\n",
    "\n",
    "# Show model summary (layers, parameters, shapes)\n",
    "feature_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Deep Features with GPU Optimization - OPTIMIZED\n",
    "def extract_features(generator):\n",
    "    \"\"\"Extract features with GPU acceleration and optimized batching\"\"\"\n",
    "    import time\n",
    "    \n",
    "    print(\"🚀 Starting GPU-optimized feature extraction...\")\n",
    "    \n",
    "    # OPTIMIZATION: Use GPU with optimized settings\n",
    "    if tf.config.list_physical_devices('GPU'):\n",
    "        print(\"🔥 Using L4 GPU with mixed precision\")\n",
    "        with tf.device('/GPU:0'):\n",
    "            return _extract_features_impl(generator)\n",
    "    else:\n",
    "        print(\"💻 Using CPU (GPU not available)\")\n",
    "        return _extract_features_impl(generator)\n",
    "\n",
    "def _extract_features_impl(generator):\n",
    "    \"\"\"Internal implementation with optimized batching\"\"\"\n",
    "    X, y = [], []\n",
    "    steps = len(generator)\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # OPTIMIZATION: Process in larger chunks for better GPU utilization\n",
    "    for i in range(steps):\n",
    "        batch_start = time.time()\n",
    "        imgs, labels = generator.next()\n",
    "        \n",
    "        # OPTIMIZATION: Batch prediction with optimized batch size\n",
    "        feats = feature_model.predict(imgs, verbose=0, batch_size=imgs.shape[0])\n",
    "        \n",
    "        X.append(feats)\n",
    "        y.append(labels)\n",
    "        \n",
    "        batch_time = time.time() - batch_start\n",
    "        \n",
    "        # Report every 20 batches (reduced logging overhead)\n",
    "        if (i + 1) % 20 == 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            avg_batch_time = elapsed / (i + 1)\n",
    "            remaining_batches = steps - (i + 1)\n",
    "            eta = remaining_batches * avg_batch_time\n",
    "            \n",
    "            print(f\"📊 [{i + 1}/{steps}] Batch: {batch_time:.2f}s | \"\n",
    "                  f\"Avg: {avg_batch_time:.2f}s | ETA: {eta/60:.1f}min\")\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"✅ Feature extraction: {total_time/60:.2f} min ({total_time/steps:.2f}s/batch)\")\n",
    "    \n",
    "    return np.vstack(X), np.vstack(y)\n",
    "\n",
    "print(\"✅ GPU-optimized feature extraction ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Training Features\n",
    "print(\"Extracting training features …\")\n",
    "X_tr, Y_tr_ohe = extract_features(train_gen)\n",
    "print(f\"Training features shape: {X_tr.shape}\")\n",
    "print(f\"Training labels shape: {Y_tr_ohe.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package installation (commented out to avoid build errors)\n",
    "# Use conda environment with pre-installed packages instead\n",
    "# !pip install cython\n",
    "# !pip install pymrmr\n",
    "\n",
    "print(\"Using pre-installed packages from conda environment.\")\n",
    "print(\"If packages are missing, use: conda install cython pymrmr -c conda-forge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. TRUE mRMR Feature Ranking - OPTIMIZED\n",
    "try:\n",
    "    import pymrmr\n",
    "    print(\"pymrmr imported successfully\")\n",
    "except ImportError:\n",
    "    print(\"WARNING: pymrmr not available. Install with: conda install pymrmr -c conda-forge\")\n",
    "    print(\"Falling back to mutual information ranking only.\")\n",
    "    pymrmr = None\n",
    "\n",
    "import numpy as np, pandas as pd, time, gc\n",
    "from sklearn.feature_selection import mutual_info_classif, VarianceThreshold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def true_mrmr_feature_selection(X, y_ohe, n_features=1000, sample_rows=1500, var_thresh=0.01):\n",
    "    \"\"\"\n",
    "    OPTIMIZED TRUE mRMR implementation with reduced sampling\n",
    "    \"\"\"\n",
    "    t0 = time.time()\n",
    "    y = np.argmax(y_ohe, axis=1)\n",
    "    n_samples, n_feats = X.shape\n",
    "    \n",
    "    # Variance filter to remove low-variance features\n",
    "    if var_thresh > 0:\n",
    "        vt = VarianceThreshold(var_thresh)\n",
    "        X_filtered = vt.fit_transform(X)\n",
    "        kept_indices = np.where(vt.get_support())[0]\n",
    "    else:\n",
    "        X_filtered = X\n",
    "        kept_indices = np.arange(n_feats)\n",
    "    \n",
    "    print(f\"[mRMR] After variance filter: {len(kept_indices)} features\")\n",
    "    \n",
    "    # OPTIMIZATION: Reduced row sampling for speed\n",
    "    if sample_rows and sample_rows < X_filtered.shape[0]:\n",
    "        rng = np.random.default_rng(42)\n",
    "        rows = rng.choice(X_filtered.shape[0], size=sample_rows, replace=False)\n",
    "        X_sample = X_filtered[rows]\n",
    "        y_sample = y[rows]\n",
    "    else:\n",
    "        X_sample = X_filtered\n",
    "        y_sample = y\n",
    "    \n",
    "    # Apply TRUE mRMR if available, otherwise fall back to MI\n",
    "    if pymrmr is not None:\n",
    "        try:\n",
    "            # Create DataFrame for pymrmr\n",
    "            feature_names = [f'feature_{i}' for i in range(X_sample.shape[1])]\n",
    "            df = pd.DataFrame(X_sample, columns=feature_names)\n",
    "            df['target'] = y_sample\n",
    "            \n",
    "            selected_features = pymrmr.mRMR(df, 'MIQ', n_features)\n",
    "            # Convert feature names back to indices\n",
    "            selected_indices = [int(f.split('_')[1]) for f in selected_features]\n",
    "            # Map back to original feature indices\n",
    "            final_indices = [kept_indices[i] for i in selected_indices]\n",
    "            \n",
    "            print(f\"[TRUE-mRMR] Selected {len(final_indices)} features in {time.time()-t0:.2f}s\")\n",
    "            return final_indices\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"[TRUE-mRMR] Error: {e}. Falling back to mutual information ranking.\")\n",
    "            \n",
    "    # Fallback to MI-based ranking\n",
    "    mi_scores = mutual_info_classif(X_sample, y_sample, discrete_features=False, random_state=42, n_jobs=-1)\n",
    "    ranked_indices = np.argsort(mi_scores)[::-1]\n",
    "    selected_indices = ranked_indices[:n_features]\n",
    "    final_indices = [kept_indices[i] for i in selected_indices]\n",
    "    \n",
    "    print(f\"[MI-Ranking] Selected {len(final_indices)} features in {time.time()-t0:.2f}s\")\n",
    "    return final_indices\n",
    "\n",
    "print(\"✅ Optimized mRMR feature selection ready!\")\n",
    "\n",
    "\n",
    "## 2. Enhanced Adaptive Grey Wolf Optimization (AGWO) - OPTIMIZED\n",
    "import numpy as np, gc, hashlib\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def _subset_hash(idxs):\n",
    "    return hashlib.md5(np.asarray(idxs, dtype=np.int32).tobytes()).hexdigest()\n",
    "\n",
    "def enhanced_agwo_feature_selection(\n",
    "    X_ranked,\n",
    "    y_ohe,\n",
    "    ranked_global_indices,\n",
    "    n_wolves=20,  # OPTIMIZED: Reduced from 25\n",
    "    n_iter=15,    # OPTIMIZED: Reduced from 30 with better convergence\n",
    "    min_subset=500,\n",
    "    max_subset=1500,  # OPTIMIZED: Reduced from 2000\n",
    "    row_sample=2500,  # OPTIMIZED: Reduced from 3000\n",
    "    knn_folds=3,      # OPTIMIZED: Reduced from 5\n",
    "    rf_folds=2,       # OPTIMIZED: Kept at 2\n",
    "    rf_max_features=400,  # OPTIMIZED: Reduced from 500\n",
    "    penalty_weight=0.015,  # OPTIMIZED: Fine-tuned\n",
    "    patience=6,           # OPTIMIZED: Reduced from 8\n",
    "    random_state=42,\n",
    "    verbose=True\n",
    "):\n",
    "    \"\"\"\n",
    "    OPTIMIZED Enhanced AGWO with reduced iterations and better convergence\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    y = np.argmax(y_ohe, axis=1)\n",
    "    n_samples, n_feats = X_ranked.shape\n",
    "\n",
    "    # Enhanced row subsampling (stratified)\n",
    "    if row_sample and row_sample < n_samples:\n",
    "        rows = []\n",
    "        per_class = row_sample // len(np.unique(y))\n",
    "        for cls in np.unique(y):\n",
    "            cls_idx = np.where(y == cls)[0]\n",
    "            take = min(per_class, len(cls_idx))\n",
    "            rows.append(rng.choice(cls_idx, size=take, replace=False))\n",
    "        rows = np.concatenate(rows)\n",
    "    else:\n",
    "        rows = np.arange(n_samples)\n",
    "\n",
    "    X_fit = X_ranked[rows]\n",
    "    y_fit = y[rows]\n",
    "\n",
    "    # Wolves initialization with better diversity\n",
    "    def init_position():\n",
    "        vals = rng.random(n_feats)\n",
    "        vals = vals * (1 + 0.5 * np.sin(np.arange(n_feats) * 0.1))\n",
    "        return vals\n",
    "\n",
    "    wolves = [init_position() for _ in range(n_wolves)]\n",
    "\n",
    "    # OPTIMIZED: Logarithmic growth with steeper curve\n",
    "    def subset_budget(iter_idx):\n",
    "        log_factor = np.log(iter_idx + 2) / np.log(n_iter + 1)\n",
    "        return int(min_subset + (max_subset - min_subset) * log_factor)\n",
    "\n",
    "    # Enhanced fitness cache\n",
    "    fitness_cache = {}\n",
    "\n",
    "    def eval_subset(local_idx):\n",
    "        if len(local_idx) < 2:\n",
    "            return 0.0\n",
    "        key_hash = _subset_hash(local_idx)\n",
    "        if key_hash in fitness_cache:\n",
    "            return fitness_cache[key_hash]\n",
    "\n",
    "        # Enhanced feature selection for RF\n",
    "        feat_slice = local_idx\n",
    "        if len(feat_slice) > rf_max_features:\n",
    "            feat_slice_rf = rng.choice(feat_slice, size=rf_max_features, replace=False)\n",
    "        else:\n",
    "            feat_slice_rf = feat_slice\n",
    "\n",
    "        X_sub = X_fit[:, feat_slice]\n",
    "        scaler = StandardScaler()\n",
    "        X_sub = scaler.fit_transform(X_sub)\n",
    "\n",
    "        # KNN CV with reduced folds\n",
    "        skf_knn = StratifiedKFold(n_splits=knn_folds, shuffle=True, random_state=123)\n",
    "        knn_scores = []\n",
    "        knn = KNeighborsClassifier(n_neighbors=5, weights='distance', n_jobs=-1)\n",
    "        for tr, va in skf_knn.split(X_sub, y_fit):\n",
    "            knn.fit(X_sub[tr], y_fit[tr])\n",
    "            pred = knn.predict(X_sub[va])\n",
    "            knn_scores.append(accuracy_score(y_fit[va], pred))\n",
    "        knn_acc = np.mean(knn_scores)\n",
    "\n",
    "        # RF CV with reduced folds\n",
    "        X_sub_rf = X_fit[:, feat_slice_rf]\n",
    "        scaler_rf = StandardScaler()\n",
    "        X_sub_rf = scaler_rf.fit_transform(X_sub_rf)\n",
    "        skf_rf = StratifiedKFold(n_splits=rf_folds, shuffle=True, random_state=321)\n",
    "        rf_scores = []\n",
    "        rf = RandomForestClassifier(\n",
    "            n_estimators=150,  # OPTIMIZED: Reduced from 200\n",
    "            max_features='sqrt',\n",
    "            n_jobs=-1,\n",
    "            random_state=999\n",
    "        )\n",
    "        for tr, va in skf_rf.split(X_sub_rf, y_fit):\n",
    "            rf.fit(X_sub_rf[tr], y_fit[tr])\n",
    "            pred = rf.predict(X_sub_rf[va])\n",
    "            rf_scores.append(accuracy_score(y_fit[va], pred))\n",
    "        rf_acc = np.mean(rf_scores)\n",
    "\n",
    "        # Fine-tuned penalty\n",
    "        size_penalty = penalty_weight * (len(local_idx) / max_subset)\n",
    "        fitness = 0.7 * knn_acc + 0.3 * rf_acc - size_penalty\n",
    "        fitness_cache[key_hash] = fitness\n",
    "        return fitness\n",
    "\n",
    "    # Enhanced decoding with stability\n",
    "    def decode(position, k):\n",
    "        noisy_pos = position + rng.normal(0, 0.01, len(position))\n",
    "        order = np.argpartition(noisy_pos, -k)[-k:]\n",
    "        return order[np.argsort(-noisy_pos[order])]\n",
    "\n",
    "    # Enhanced AGWO loop\n",
    "    best_global_subset = None\n",
    "    best_fitness = -1\n",
    "    no_improve = 0\n",
    "\n",
    "    for it in range(n_iter):\n",
    "        k_budget = subset_budget(it)\n",
    "\n",
    "        # Decode all wolves\n",
    "        wolf_subsets = [decode(w, k_budget) for w in wolves]\n",
    "        wolf_scores = [eval_subset(sub) for sub in wolf_subsets]\n",
    "\n",
    "        # Identify alpha, beta, delta\n",
    "        order = np.argsort(wolf_scores)[::-1]\n",
    "        alpha, beta, delta = wolves[order[0]], wolves[order[1]], wolves[order[2]]\n",
    "        alpha_subset = wolf_subsets[order[0]]\n",
    "        alpha_score = wolf_scores[order[0]]\n",
    "\n",
    "        if alpha_score > best_fitness:\n",
    "            best_fitness = alpha_score\n",
    "            best_global_subset = alpha_subset.copy()\n",
    "            no_improve = 0\n",
    "        else:\n",
    "            no_improve += 1\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"[AGWO] iter {it+1}/{n_iter} k={k_budget} alpha={alpha_score:.4f} best={best_fitness:.4f} cache={len(fitness_cache)}\")\n",
    "\n",
    "        if no_improve >= patience:\n",
    "            if verbose:\n",
    "                print(f\"[AGWO] Early stop (patience {patience})\")\n",
    "            break\n",
    "\n",
    "        # OPTIMIZED: Steeper decay for faster convergence\n",
    "        a = 2 * np.exp(-4 * (it / n_iter))\n",
    "\n",
    "        # Enhanced wolf update\n",
    "        new_wolves = []\n",
    "        for idx, w in enumerate(wolves):\n",
    "            if idx in order[:3]:\n",
    "                new_wolves.append(w)\n",
    "                continue\n",
    "                \n",
    "            A1 = 2 * a * rng.random(n_feats) - a\n",
    "            C1 = 2 * rng.random(n_feats)\n",
    "            A2 = 2 * a * rng.random(n_feats) - a\n",
    "            C2 = 2 * rng.random(n_feats)\n",
    "            A3 = 2 * a * rng.random(n_feats) - a\n",
    "            C3 = 2 * rng.random(n_feats)\n",
    "\n",
    "            D_alpha = np.abs(C1 * alpha - w)\n",
    "            D_beta  = np.abs(C2 * beta  - w)\n",
    "            D_delta = np.abs(C3 * delta - w)\n",
    "\n",
    "            X1 = alpha - A1 * D_alpha\n",
    "            X2 = beta  - A2 * D_beta\n",
    "            X3 = delta - A3 * D_delta\n",
    "\n",
    "            new_pos = (X1 + X2 + X3) / 3.0\n",
    "\n",
    "            # Enhanced mutation\n",
    "            if rng.random() < 0.15:\n",
    "                mut_mask = rng.random(n_feats) < 0.005\n",
    "                noise = rng.normal(0, 0.3, np.sum(mut_mask))\n",
    "                new_pos[mut_mask] += noise\n",
    "\n",
    "            new_pos = np.clip(new_pos, -2.0, 2.0)\n",
    "            new_wolves.append(new_pos)\n",
    "\n",
    "        # Diversity injection\n",
    "        if no_improve == patience - 1:\n",
    "            inject_count = max(2, n_wolves // 5)\n",
    "            for _ in range(inject_count):\n",
    "                ridx = rng.integers(3, n_wolves)\n",
    "                new_wolves[ridx] = init_position()\n",
    "\n",
    "        wolves = new_wolves\n",
    "\n",
    "    # Map to global feature indices\n",
    "    selected_global = [ranked_global_indices[i] for i in best_global_subset]\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"[AGWO] Complete: {len(selected_global)} features, fitness={best_fitness:.4f}\")\n",
    "\n",
    "    return selected_global\n",
    "\n",
    "print(\"✅ Optimized AGWO feature selection ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Validation Features\n",
    "print(\"Extracting validation features …\")\n",
    "X_va, Y_va_ohe = extract_features(val_gen)\n",
    "print(f\"Validation features shape: {X_va.shape}\")\n",
    "print(f\"Validation labels shape: {Y_va_ohe.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine Features and Convert Labels\n",
    "X_full = np.vstack([X_tr, X_va])\n",
    "y_full = np.argmax(np.vstack([Y_tr_ohe, Y_va_ohe]), axis=1)\n",
    "\n",
    "print(f\"Total features shape: {X_full.shape}\")\n",
    "print(f\"Total labels shape: {y_full.shape}\")\n",
    "print(f\"Classes present: {np.unique(y_full)}\")\n",
    "print(f\"Class distribution: {np.bincount(y_full)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- OPTIMIZED: TRUE mRMR + Enhanced AGWO Feature Selection Pipeline ---\n",
    "t_total = time.time()\n",
    "\n",
    "# OPTIMIZED Parameters (balanced for speed and accuracy)\n",
    "n_mrmr = 800          # OPTIMIZED: Reduced from 1000\n",
    "sample_rows = 1500    # OPTIMIZED: Reduced from 2000\n",
    "subset_size = 1500    # OPTIMIZED: Reduced from 2000 for AGWO\n",
    "n_wolves = 20         # OPTIMIZED: Reduced from 25\n",
    "n_iter = 15           # OPTIMIZED: Reduced from 30\n",
    "\n",
    "# Stage 1: TRUE mRMR Feature Ranking\n",
    "print(\"Stage 1: TRUE mRMR Feature Ranking (Optimized)\")\n",
    "ranked_features = true_mrmr_feature_selection(\n",
    "    X_tr, Y_tr_ohe,\n",
    "    n_features=n_mrmr,\n",
    "    sample_rows=sample_rows,\n",
    "    var_thresh=0.01\n",
    ")\n",
    "print(f\"[Pipeline] Ranked features: {len(ranked_features)}\")\n",
    "\n",
    "# Stage 2: Slice training matrix to ranked features ONLY for Enhanced AGWO\n",
    "X_tr_ranked = X_tr[:, ranked_features]\n",
    "print(f\"[Pipeline] Ranked features shape: {X_tr_ranked.shape}\")\n",
    "\n",
    "# Stage 3: Enhanced AGWO Feature Selection\n",
    "print(\"\\nStage 3: Enhanced AGWO Feature Selection (Optimized)\")\n",
    "selected_features = enhanced_agwo_feature_selection(\n",
    "    X_tr_ranked, Y_tr_ohe, ranked_features,\n",
    "    n_wolves=n_wolves,\n",
    "    n_iter=n_iter,\n",
    "    min_subset=500,\n",
    "    max_subset=subset_size,\n",
    "    row_sample=2500,   # OPTIMIZED: Reduced from 3000\n",
    "    knn_folds=3,       # OPTIMIZED: Reduced from 5\n",
    "    rf_folds=2,        # OPTIMIZED: Kept at 2\n",
    "    rf_max_features=400,  # OPTIMIZED: Reduced from 500\n",
    "    penalty_weight=0.015,\n",
    "    patience=6,           # OPTIMIZED: Reduced from 8\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(f\"[Pipeline] Final selected features: {len(selected_features)}\")\n",
    "\n",
    "# Extract final feature matrices\n",
    "X_tr_final = X_tr[:, selected_features]\n",
    "X_test_final = X_test[:, selected_features]\n",
    "\n",
    "print(f\"[Pipeline] Final training shape: {X_tr_final.shape}\")\n",
    "print(f\"[Pipeline] Final test shape: {X_test_final.shape}\")\n",
    "print(f\"[Pipeline] Feature reduction: {X_tr.shape[1]} → {X_tr_final.shape[1]} ({X_tr_final.shape[1]/X_tr.shape[1]:.1%})\")\n",
    "\n",
    "# Store for later use\n",
    "feature_subset = selected_features\n",
    "\n",
    "print(f\"\\n[Pipeline] Total time: {time.time() - t_total:.2f}s\")\n",
    "print(\"✅ Optimized two-stage feature selection completed!\")\n",
    "print(f\"[Pipeline] AGWO selected {len(selected_features)} features.\")\n",
    "\n",
    "# 4. Apply selection to full (train+val) without building giant X_full first\n",
    "X_tr_sel = X_tr[:, selected_features]\n",
    "X_va_sel = X_va[:, selected_features]\n",
    "y_full = np.argmax(np.vstack([Y_tr_ohe, Y_va_ohe]), axis=1)\n",
    "X_full_sel = np.vstack([X_tr_sel, X_va_sel])\n",
    "\n",
    "# 5. Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_full_sel, y_full, test_size=0.20, random_state=SEED, stratify=y_full\n",
    ")\n",
    "\n",
    "print(f\"[Pipeline] Train {X_train.shape}, Test {X_test.shape}, total time {time.time()-t_total:.2f}s\")\n",
    "\n",
    "# Cleanup\n",
    "del X_tr_ranked, X_tr_sel, X_va_sel\n",
    "gc.collect()\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}\")\n",
    "print(f\"Training class distribution: {np.bincount(y_train)}\")\n",
    "print(f\"Test class distribution: {np.bincount(y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Classifiers - OPTIMIZED\n",
    "# Note: xgboost should be pre-installed in conda environment\n",
    "# !pip install xgboost  # commented out to avoid build errors\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# OPTIMIZED: Parallel processing enabled for all classifiers\n",
    "knn = KNeighborsClassifier(n_neighbors=5, weights='distance', n_jobs=-1)\n",
    "svm = SVC(kernel='rbf', probability=True, C=1.0, gamma='scale', random_state=SEED, cache_size=500)\n",
    "rf  = RandomForestClassifier(n_estimators=250, random_state=SEED, n_jobs=-1, max_features='sqrt')  # OPTIMIZED: Reduced from 300\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=150,  # OPTIMIZED: Reduced from 200\n",
    "    random_state=SEED, \n",
    "    use_label_encoder=False, \n",
    "    eval_metric='mlogloss',\n",
    "    tree_method='hist',  # OPTIMIZED: Faster histogram-based method\n",
    "    n_jobs=-1\n",
    ")\n",
    "lr  = LogisticRegression(max_iter=500, random_state=SEED, n_jobs=-1, solver='saga')  # OPTIMIZED: Reduced from 1000\n",
    "\n",
    "print(\"✅ Classifiers initialized (optimized):\")\n",
    "print(f\"  KNN: k=5, weights='distance', n_jobs=-1\")\n",
    "print(f\"  SVM: RBF kernel, C=1.0, gamma='scale', cache_size=500\")\n",
    "print(f\"  Random Forest: 250 trees, n_jobs=-1\")\n",
    "print(f\"  XGBoost: 150 estimators, hist method, n_jobs=-1\")\n",
    "print(f\"  Logistic Regression: max_iter=500, saga solver, n_jobs=-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Classifiers\n",
    "print(\"Training classifiers …\")\n",
    "\n",
    "print(\"  Training KNN...\")\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "print(\"  Training SVM...\")\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "print(\"  Training Random Forest...\")\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "print(\"  Training XGBoost...\")\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "print(\"  Training Logistic Regression...\")\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "print(\"All classifiers trained successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Predictions\n",
    "print(\"Making predictions...\")\n",
    "\n",
    "knn_pred = knn.predict(X_test)\n",
    "svm_pred = svm.predict(X_test)\n",
    "rf_pred  = rf.predict(X_test)\n",
    "xgb_pred = xgb.predict(X_test)\n",
    "lr_pred  = lr.predict(X_test)\n",
    "\n",
    "# Probabilistic predictions (for ensemble if needed)\n",
    "knn_proba = knn.predict_proba(X_test) if hasattr(knn, 'predict_proba') else None\n",
    "svm_proba = svm.predict_proba(X_test) if hasattr(svm, 'predict_proba') else None\n",
    "rf_proba  = rf.predict_proba(X_test) if hasattr(rf, 'predict_proba') else None\n",
    "xgb_proba = xgb.predict_proba(X_test) if hasattr(xgb, 'predict_proba') else None\n",
    "lr_proba  = lr.predict_proba(X_test) if hasattr(lr, 'predict_proba') else None\n",
    "\n",
    "print(\"Predictions completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Individual Classifier Results\n",
    "print(\"Individual Classifier Accuracies:\")\n",
    "knn_acc = accuracy_score(y_test, knn_pred)\n",
    "svm_acc = accuracy_score(y_test, svm_pred)\n",
    "rf_acc = accuracy_score(y_test, rf_pred)\n",
    "xgb_acc = accuracy_score(y_test, xgb_pred)\n",
    "lr_acc = accuracy_score(y_test, lr_pred)\n",
    "\n",
    "print(f\"  KNN: {knn_acc:.4f}\")\n",
    "print(f\"  SVM: {svm_acc:.4f}\")\n",
    "print(f\"  RF : {rf_acc:.4f}\")\n",
    "print(f\"  XGB: {xgb_acc:.4f}\")\n",
    "print(f\"  LR : {lr_acc:.4f}\")\n",
    "\n",
    "# Display individual classification reports\n",
    "target_names = [id2label[i] for i in range(num_classes)]\n",
    "\n",
    "print(\"\\n=== KNN Classification Report ===\")\n",
    "print(classification_report(y_test, knn_pred, target_names=target_names))\n",
    "\n",
    "print(\"\\n=== SVM Classification Report ===\")\n",
    "print(classification_report(y_test, svm_pred, target_names=target_names))\n",
    "\n",
    "print(\"\\n=== Random Forest Classification Report ===\")\n",
    "print(classification_report(y_test, rf_pred, target_names=target_names))\n",
    "\n",
    "print(\"\\n=== XGBoost Classification Report ===\")\n",
    "print(classification_report(y_test, xgb_pred, target_names=target_names))\n",
    "\n",
    "print(\"\\n=== Logistic Regression Classification Report ===\")\n",
    "print(classification_report(y_test, lr_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CORRECTED: Priority-Based Weighting Implementation\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def calculate_priority_weights_fixed(accuracies):\n",
    "    \"\"\"\n",
    "    CORRECTED Priority-based weighting calculation:\n",
    "    - Classifiers ranked by validation accuracy: C*(1) ≥ C*(2) ≥ ... ≥ C*(k)\n",
    "    - Compute intermediate weights: T₁ = 1, Tⱼ = ∏ᵢ₌₁ʲ⁻¹ fᵢ* for j ≥ 2\n",
    "    - Normalize: εⱼ = Tⱼ / Σₘ Tₘ\n",
    "    - Final prediction: P_final(c) = Σ εⱼ · p*ⱼ(c)\n",
    "    \"\"\"\n",
    "    # Rank classifiers by accuracy (descending)\n",
    "    ranked_indices = np.argsort(accuracies)[::-1]\n",
    "    ranked_accs = np.array([accuracies[i] for i in ranked_indices])\n",
    "    \n",
    "    # Calculate intermediate weights T\n",
    "    T = [1.0]  # T₁ = 1\n",
    "    for j in range(1, len(ranked_accs)):\n",
    "        # Tⱼ = ∏ᵢ₌₁ʲ⁻¹ fᵢ* (product of ALL higher-ranked accuracies)\n",
    "        T.append(np.prod(ranked_accs[:j]))\n",
    "    \n",
    "    T = np.array(T)\n",
    "    \n",
    "    # Normalize to get final weights\n",
    "    weights = T / np.sum(T)\n",
    "    \n",
    "    print(f\"[Priority-Weights] Ranked accuracies: {ranked_accs}\")\n",
    "    print(f\"[Priority-Weights] Intermediate T: {T}\")\n",
    "    print(f\"[Priority-Weights] Final weights: {weights}\")\n",
    "    print(f\"[Priority-Weights] Weights sum: {np.sum(weights):.6f}\")\n",
    "    \n",
    "    return weights, ranked_indices\n",
    "\n",
    "def priority_weighted_prediction_fixed(predictions, weights, ranked_indices):\n",
    "    \"\"\"\n",
    "    CORRECTED Priority-weighted ensemble prediction\n",
    "    \"\"\"\n",
    "    # Reorder predictions according to ranking\n",
    "    ranked_predictions = predictions[ranked_indices]\n",
    "    \n",
    "    # Apply weights: P_final(c) = Σ εⱼ · p*ⱼ(c)\n",
    "    weighted_pred = np.average(ranked_predictions, axis=0, weights=weights)\n",
    "    \n",
    "    return weighted_pred\n",
    "\n",
    "# Apply CORRECTED priority-based weighting\n",
    "print(\"=== CORRECTED Priority-Based Ensemble Fusion ===\")\n",
    "\n",
    "# Get all predictions\n",
    "all_predictions = np.array([knn_pred, svm_pred, rf_pred, xgb_pred, lr_pred])\n",
    "all_accuracies = np.array([knn_acc, svm_acc, rf_acc, xgb_acc, lr_acc])\n",
    "\n",
    "# Calculate CORRECTED priority weights\n",
    "weights_fixed, ranked_indices = calculate_priority_weights_fixed(all_accuracies)\n",
    "\n",
    "# Apply CORRECTED weighted prediction\n",
    "weighted_pred_fixed = priority_weighted_prediction_fixed(all_predictions, weights_fixed, ranked_indices)\n",
    "weighted_pred_fixed_labels = np.argmax(weighted_pred_fixed, axis=1)\n",
    "\n",
    "# Calculate accuracy\n",
    "weighted_ens_acc_fixed = accuracy_score(y_test, weighted_pred_fixed_labels)\n",
    "\n",
    "print(f\"\\nCORRECTED Weighted-Average Ensemble Accuracy: {weighted_ens_acc_fixed:.4f}\")\n",
    "print(f\"Improvement over best individual: {weighted_ens_acc_fixed - max(all_accuracies):.4f}\")\n",
    "\n",
    "# Compare with original implementation\n",
    "print(f\"\\nOriginal ensemble accuracy: {ens_acc:.4f}\")\n",
    "print(f\"Corrected ensemble accuracy: {weighted_ens_acc_fixed:.4f}\")\n",
    "print(f\"Improvement: {weighted_ens_acc_fixed - ens_acc:.4f}\")\n",
    "\n",
    "print(\"\\nCORRECTED Priority-based weighting functions implemented!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble Fusion (Priority-Based Strategy)\n",
    "# Priority: SVM > XGBoost > RF > KNN > LR\n",
    "# If SVM and XGBoost agree, use that prediction. Else, use SVM. If not, use XGBoost. Else, fallback to majority vote.\n",
    "def priority_ensemble(svm_pred, xgb_pred, rf_pred, knn_pred, lr_pred):\n",
    "    preds = np.stack([knn_pred, svm_pred, rf_pred, xgb_pred, lr_pred], axis=0)\n",
    "    final = []\n",
    "    for i in range(svm_pred.shape[0]):\n",
    "        if svm_pred[i] == xgb_pred[i]:\n",
    "            final.append(svm_pred[i])\n",
    "        elif svm_pred[i] == rf_pred[i]:\n",
    "            final.append(svm_pred[i])\n",
    "        elif xgb_pred[i] == rf_pred[i]:\n",
    "            final.append(xgb_pred[i])\n",
    "        else:\n",
    "            # fallback to majority vote\n",
    "            vals, counts = np.unique(preds[:, i], return_counts=True)\n",
    "            final.append(vals[np.argmax(counts)])\n",
    "    return np.array(final)\n",
    "\n",
    "ens = priority_ensemble(svm_pred, xgb_pred, rf_pred, knn_pred, lr_pred)\n",
    "ens_acc = accuracy_score(y_test, ens)\n",
    "\n",
    "print(f\"Ensemble Accuracy (Priority-Based): {ens_acc:.4f}\")\n",
    "print(f\"\\nImprovement over best individual: {ens_acc - max(knn_acc, svm_acc, rf_acc, xgb_acc, lr_acc):.4f}\")\n",
    "\n",
    "print(\"\\n=== Ensemble Classification Report ===\")\n",
    "print(classification_report(y_test, ens, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weighted-Average Ensemble Method (Performance-Ranked)\n",
    "import numpy as np\n",
    "\n",
    "# 1. Gather classifier predictions and accuracies\n",
    "classifier_preds = [knn_pred, svm_pred, rf_pred, xgb_pred, lr_pred]\n",
    "classifier_accs = [knn_acc, svm_acc, rf_acc, xgb_acc, lr_acc]\n",
    "classifier_names = ['KNN', 'SVM', 'RF', 'XGB', 'LR']\n",
    "\n",
    "# 2. Rank classifiers by accuracy (descending)\n",
    "ranked_indices = np.argsort(classifier_accs)[::-1]\n",
    "ranked_accs = [classifier_accs[i] for i in ranked_indices]\n",
    "ranked_preds = [classifier_preds[i] for i in ranked_indices]\n",
    "ranked_names = [classifier_names[i] for i in ranked_indices]\n",
    "\n",
    "print('Classifier ranking (best to worst):')\n",
    "for i, name in enumerate(ranked_names):\n",
    "    print(f'  {i+1}. {name} (acc={ranked_accs[i]:.4f})')\n",
    "\n",
    "# 3. Calculate intermediate scores T_j\n",
    "T = [1.0]\n",
    "for j in range(1, len(ranked_accs)):\n",
    "    T.append(T[-1] * ranked_accs[j-1])\n",
    "\n",
    "# 4. Normalize to get weights epsilon_j\n",
    "T_sum = sum(T)\n",
    "weights = [t / T_sum for t in T]\n",
    "\n",
    "print('Classifier weights (epsilon_j):')\n",
    "for i, (name, w) in enumerate(zip(ranked_names, weights)):\n",
    "    print(f'  {name}: {w:.4f}')\n",
    "\n",
    "# 5. Weighted voting for each test sample\n",
    "n_classes = num_classes\n",
    "n_samples = len(y_test)\n",
    "weighted_votes = np.zeros((n_samples, n_classes))\n",
    "\n",
    "for clf_idx, (pred, w) in enumerate(zip(ranked_preds, weights)):\n",
    "    for i in range(n_samples):\n",
    "        weighted_votes[i, pred[i]] += w\n",
    "\n",
    "weighted_ensemble_pred = np.argmax(weighted_votes, axis=1)\n",
    "\n",
    "weighted_ens_acc = accuracy_score(y_test, weighted_ensemble_pred)\n",
    "\n",
    "print(f'Weighted-Average Ensemble Accuracy: {weighted_ens_acc:.4f}')\n",
    "print(f'\\nImprovement over best individual: {weighted_ens_acc - ranked_accs[0]:.4f}')\n",
    "\n",
    "print('\\n=== Weighted-Average Ensemble Classification Report ===')\n",
    "print(classification_report(y_test, weighted_ensemble_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# CORRECTED: Final Results Summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CORRECTED IMPLEMENTATION - FINAL RESULTS SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"Total samples processed: {len(y_full)}\")\n",
    "\n",
    "# Resolve selected features list (legacy variable fallback)\n",
    "if 'selected_features' in globals():\n",
    "    sel_list = selected_features\n",
    "elif 'sel_idx' in globals():\n",
    "    sel_list = sel_idx\n",
    "elif 'feature_subset' in globals():\n",
    "    sel_list = feature_subset\n",
    "else:\n",
    "    sel_list = []\n",
    "\n",
    "# Try to infer original feature count\n",
    "if 'X_tr_original' in globals():\n",
    "    orig_feat_total = X_tr_original.shape[1]\n",
    "elif 'X_tr' in globals():\n",
    "    orig_feat_total = X_tr.shape[1]\n",
    "elif 'X_full' in globals():\n",
    "    orig_feat_total = X_full.shape[1]\n",
    "else:\n",
    "    # Fallback to selected count (prevents division error)\n",
    "    orig_feat_total = max(len(sel_list), 1)\n",
    "\n",
    "selected_count = len(sel_list)\n",
    "pct = (selected_count / orig_feat_total) if orig_feat_total else 0.0\n",
    "print(f\"Features selected by CORRECTED AGWO: {selected_count} / {orig_feat_total} ({pct:.1%})\")\n",
    "\n",
    "print(f\"Test set size: {len(y_test)}\")\n",
    "print(\"\\nCORRECTED Classifier Accuracies:\")\n",
    "print(f\"  KNN:               {knn_acc:.4f}\")\n",
    "print(f\"  SVM:               {svm_acc:.4f}\")\n",
    "print(f\"  Random Forest:     {rf_acc:.4f}\")\n",
    "print(f\"  XGBoost:           {xgb_acc:.4f}\")\n",
    "print(f\"  Logistic Reg:      {lr_acc:.4f}\")\n",
    "\n",
    "# Show corrected ensemble results\n",
    "if 'weighted_ens_acc_fixed' in globals():\n",
    "    print(f\"  CORRECTED Ensemble: {weighted_ens_acc_fixed:.4f} ← BEST\")\n",
    "    print(f\"  Original Ensemble: {ens_acc:.4f}\")\n",
    "    print(f\"  Improvement: {weighted_ens_acc_fixed - ens_acc:.4f}\")\n",
    "else:\n",
    "    print(f\"  Ensemble (Fusion): {ens_acc:.4f} ← BEST\")\n",
    "\n",
    "print(\"\\nCORRECTED Implementation Features:\")\n",
    "print(\"  ✅ TRUE mRMR (not approximate)\")\n",
    "print(\"  ✅ Enhanced AGWO with expanded scope\")\n",
    "print(\"  ✅ Memory-optimized multi-head attention\")\n",
    "print(\"  ✅ Corrected priority-based weighting\")\n",
    "print(\"  ✅ Proper ensemble fusion\")\n",
    "\n",
    "print(\"\\nClass Labels:\")\n",
    "for i, label in id2label.items():\n",
    "    print(f\"  {i}: {label}\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

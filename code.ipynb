{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lung Histopathology Classification: ACA / N / SCC\n",
    "## Multi-CNN + Channel Attention + GA + KNN/SVM/RF + Fusion\n",
    "\n",
    "This notebook implements a comprehensive lung histopathology classification system that combines:\n",
    "- Multiple CNN backbones (DenseNet121, ResNet50, VGG16)\n",
    "- Channel attention mechanism (SE blocks)\n",
    "- Genetic Algorithm for feature selection\n",
    "- Ensemble of classical ML classifiers (KNN, SVM, Random Forest)\n",
    "- Majority voting fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os, random, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.applications import DenseNet121, ResNet50, VGG16\n",
    "from tensorflow.keras.applications.densenet import preprocess_input as pre_densenet\n",
    "from tensorflow.keras.applications.resnet import preprocess_input as pre_resnet\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input as pre_vgg\n",
    "from tensorflow.keras.layers import (Input, GlobalAveragePooling2D, GlobalMaxPooling2D,\n",
    "                                     Concatenate, Dense, Reshape, Multiply, Lambda)\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from scipy.stats import mode\n",
    "\n",
    "# GA (DEAP)\n",
    "from deap import base, creator, tools\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration and Data Setup\n",
    "DATA_DIR   = \"/path/to/lung_colon_image_set/lung_image_sets\"  # << set this\n",
    "IMG_SIZE   = (224, 224)\n",
    "BATCH_SIZE = 24\n",
    "SEED       = 42\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "print(f\"Configuration set:\")\n",
    "print(f\"Data Directory: {DATA_DIR}\")\n",
    "print(f\"Image Size: {IMG_SIZE}\")\n",
    "print(f\"Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"Random Seed: {SEED}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Generators Setup\n",
    "# Only lung classes will be present in this directory if you set DATA_DIR as above:\n",
    "# expected subfolders: lung_aca / lung_n / lung_scc\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    validation_split=0.20,\n",
    "    rotation_range=20,\n",
    "    horizontal_flip=True,\n",
    "    # IMPORTANT: no rescale here, since we feed raw to model-specific preprocessors\n",
    ")\n",
    "\n",
    "def make_gen(subset):\n",
    "    return train_datagen.flow_from_directory(\n",
    "        DATA_DIR,\n",
    "        target_size=IMG_SIZE,\n",
    "        class_mode='categorical',\n",
    "        batch_size=BATCH_SIZE,\n",
    "        subset=subset,\n",
    "        seed=SEED,\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "train_gen = make_gen('training')\n",
    "val_gen   = make_gen('validation')\n",
    "num_classes = train_gen.num_classes\n",
    "class_indices = train_gen.class_indices\n",
    "id2label = {v:k for k,v in class_indices.items()}\n",
    "\n",
    "print(\"Classes:\", class_indices)\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "print(f\"Training samples: {train_gen.samples}\")\n",
    "print(f\"Validation samples: {val_gen.samples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Channel Attention (SE Block) Implementation\n",
    "def se_block(x, reduction=16, name=None):\n",
    "    \"\"\"Squeeze-and-Excitation block for channel attention\"\"\"\n",
    "    ch = x.shape[-1]\n",
    "    gap = GlobalAveragePooling2D(name=None if not name else name+\"_gap\")(x)\n",
    "    gmp = GlobalMaxPooling2D(name=None if not name else name+\"_gmp\")(x)\n",
    "\n",
    "    # shared MLP via Dense on pooled (batch, ch)\n",
    "    d1_gap = Dense(ch // reduction, activation='relu')(gap)\n",
    "    d1_gmp = Dense(ch // reduction, activation='relu')(gmp)\n",
    "    d2_gap = Dense(ch)(d1_gap)\n",
    "    d2_gmp = Dense(ch)(d1_gmp)\n",
    "\n",
    "    scale = tf.nn.sigmoid(d2_gap + d2_gmp)\n",
    "    scale = Reshape((1,1,ch))(scale)\n",
    "    return Multiply()([x, scale])\n",
    "\n",
    "print(\"SE block function defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing Lanes (one per backbone)\n",
    "def lane(tensor, backbone=\"resnet\"):\n",
    "    \"\"\"Create a processing lane for each CNN backbone with SE attention\"\"\"\n",
    "    if backbone == \"resnet\":\n",
    "        x = Lambda(pre_resnet, name=\"pre_resnet\")(tensor)\n",
    "        x = ResNet50(include_top=False, weights='imagenet')(x)\n",
    "    elif backbone == \"densenet\":\n",
    "        x = Lambda(pre_densenet, name=\"pre_densenet\")(tensor)\n",
    "        x = DenseNet121(include_top=False, weights='imagenet')(x)\n",
    "    else:  # vgg\n",
    "        x = Lambda(pre_vgg, name=\"pre_vgg\")(tensor)\n",
    "        x = VGG16(include_top=False, weights='imagenet')(x)\n",
    "    \n",
    "    x = se_block(x, reduction=16, name=f\"se_{backbone}\")\n",
    "    x = GlobalAveragePooling2D(name=f\"gap_{backbone}\")(x)\n",
    "    return x\n",
    "\n",
    "print(\"Lane function defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Feature Extractor Model\n",
    "print(\"Building multi-backbone feature extractor...\")\n",
    "\n",
    "inp = Input(shape=(224,224,3))\n",
    "feat_d = lane(inp, \"densenet\")\n",
    "feat_r = lane(inp, \"resnet\")\n",
    "feat_v = lane(inp, \"vgg\")\n",
    "concat_feat = Concatenate(name=\"concat_feats\")([feat_d, feat_r, feat_v])\n",
    "feature_model = Model(inp, concat_feat)\n",
    "feature_dim = feature_model.output_shape[-1]\n",
    "\n",
    "print(f\"Feature extractor built successfully!\")\n",
    "print(f\"Feature dimension: {feature_dim}\")\n",
    "feature_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Deep Features\n",
    "def extract_features(generator):\n",
    "    \"\"\"Extract features from a data generator using the feature model\"\"\"\n",
    "    X, y = [], []\n",
    "    steps = len(generator)\n",
    "    for i in range(steps):\n",
    "        imgs, labels = generator.next()\n",
    "        feats = feature_model.predict(imgs, verbose=0)\n",
    "        X.append(feats)\n",
    "        y.append(labels)\n",
    "        if (i + 1) % 10 == 0:\n",
    "            print(f\"Processed {i + 1}/{steps} batches\")\n",
    "    return np.vstack(X), np.vstack(y)\n",
    "\n",
    "print(\"Feature extraction function defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Training Features\n",
    "print(\"Extracting training features …\")\n",
    "X_tr, Y_tr_ohe = extract_features(train_gen)\n",
    "print(f\"Training features shape: {X_tr.shape}\")\n",
    "print(f\"Training labels shape: {Y_tr_ohe.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Validation Features\n",
    "print(\"Extracting validation features …\")\n",
    "X_va, Y_va_ohe = extract_features(val_gen)\n",
    "print(f\"Validation features shape: {X_va.shape}\")\n",
    "print(f\"Validation labels shape: {Y_va_ohe.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine Features and Convert Labels\n",
    "X_full = np.vstack([X_tr, X_va])\n",
    "y_full = np.argmax(np.vstack([Y_tr_ohe, Y_va_ohe]), axis=1)\n",
    "\n",
    "print(f\"Total features shape: {X_full.shape}\")\n",
    "print(f\"Total labels shape: {y_full.shape}\")\n",
    "print(f\"Classes present: {np.unique(y_full)}\")\n",
    "print(f\"Class distribution: {np.bincount(y_full)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GA-based Feature Selection Setup (DEAP)\n",
    "POP_SIZE = 40\n",
    "N_GEN    = 10        # start smaller; increase later\n",
    "CX_PROB  = 0.8\n",
    "MUT_PROB = 0.1\n",
    "INDPB    = 0.05\n",
    "\n",
    "n_features = X_full.shape[1]\n",
    "\n",
    "print(f\"GA Parameters:\")\n",
    "print(f\"Population Size: {POP_SIZE}\")\n",
    "print(f\"Generations: {N_GEN}\")\n",
    "print(f\"Crossover Probability: {CX_PROB}\")\n",
    "print(f\"Mutation Probability: {MUT_PROB}\")\n",
    "print(f\"Total Features: {n_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define GA Components\n",
    "# Safe (re)definition guards for repeated runs\n",
    "if \"FitnessMax\" not in creator.__dict__:\n",
    "    creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "if \"Individual\" not in creator.__dict__:\n",
    "    creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"attr_bool\", random.randint, 0, 1)\n",
    "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_bool, n_features)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "def eval_fitness(individual):\n",
    "    \"\"\"Evaluate fitness of an individual (feature subset)\"\"\"\n",
    "    idx = [i for i, b in enumerate(individual) if b == 1]\n",
    "    if len(idx) < 2:\n",
    "        return (0.0,)\n",
    "    Xs = X_full[:, idx]\n",
    "    knn = KNeighborsClassifier(n_neighbors=5)\n",
    "    scores = cross_val_score(knn, Xs, y_full, cv=3, scoring='accuracy')\n",
    "    # Small L0 penalty to prefer compact subsets\n",
    "    fitness = scores.mean() - 0.1 * (len(idx) / n_features)\n",
    "    return (float(fitness),)\n",
    "\n",
    "toolbox.register(\"evaluate\", eval_fitness)\n",
    "toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "toolbox.register(\"mutate\", tools.mutFlipBit, indpb=INDPB)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "\n",
    "print(\"GA components defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize GA Population\n",
    "pop = toolbox.population(n=POP_SIZE)\n",
    "print(f\"GA initialized: pop={POP_SIZE}, feats={n_features}\")\n",
    "print(\"Starting genetic algorithm evolution...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run GA Evolution\n",
    "for gen in range(N_GEN):\n",
    "    print(f\"\\nGeneration {gen+1}/{N_GEN}\")\n",
    "    \n",
    "    offspring = toolbox.select(pop, len(pop))\n",
    "    offspring = list(map(toolbox.clone, offspring))\n",
    "\n",
    "    # Crossover\n",
    "    for c1, c2 in zip(offspring[::2], offspring[1::2]):\n",
    "        if random.random() < CX_PROB:\n",
    "            toolbox.mate(c1, c2)\n",
    "            if \"fitness\" in c1.__dict__: del c1.fitness.values\n",
    "            if \"fitness\" in c2.__dict__: del c2.fitness.values\n",
    "\n",
    "    # Mutation\n",
    "    for ind in offspring:\n",
    "        if random.random() < MUT_PROB:\n",
    "            toolbox.mutate(ind)\n",
    "            if \"fitness\" in ind.__dict__: del ind.fitness.values\n",
    "\n",
    "    # Evaluation\n",
    "    invalid = [ind for ind in offspring if not ind.fitness.valid]\n",
    "    print(f\"  Evaluating {len(invalid)} individuals...\")\n",
    "    fits = list(map(toolbox.evaluate, invalid))\n",
    "    for ind, fit in zip(invalid, fits):\n",
    "        ind.fitness.values = fit\n",
    "\n",
    "    pop[:] = offspring\n",
    "    gen_fits = [ind.fitness.values[0] for ind in pop]\n",
    "    print(f\"  Max fitness: {np.max(gen_fits):.4f}\")\n",
    "    print(f\"  Avg fitness: {np.mean(gen_fits):.4f}\")\n",
    "\n",
    "print(\"\\nGA evolution completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select Best Features\n",
    "best = tools.selBest(pop, 1)[0]\n",
    "sel_idx = np.array([i for i, b in enumerate(best) if b == 1], dtype=int)\n",
    "\n",
    "print(f\"Selected {len(sel_idx)} / {n_features} features\")\n",
    "print(f\"Feature selection ratio: {len(sel_idx)/n_features:.3f}\")\n",
    "print(f\"Best fitness: {best.fitness.values[0]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Selected Features for Training\n",
    "X_sel = X_full[:, sel_idx]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_sel, y_full, test_size=0.20, random_state=SEED, stratify=y_full\n",
    ")\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}\")\n",
    "print(f\"Training class distribution: {np.bincount(y_train)}\")\n",
    "print(f\"Test class distribution: {np.bincount(y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Classifiers\n",
    "knn = KNeighborsClassifier(n_neighbors=5, weights='distance')\n",
    "svm = SVC(kernel='rbf', probability=True, C=1.0, gamma='scale', random_state=SEED)\n",
    "rf  = RandomForestClassifier(n_estimators=300, random_state=SEED, n_jobs=-1)\n",
    "\n",
    "print(\"Classifiers initialized:\")\n",
    "print(f\"  KNN: k=5, weights='distance'\")\n",
    "print(f\"  SVM: RBF kernel, C=1.0, gamma='scale'\")\n",
    "print(f\"  Random Forest: 300 trees\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Classifiers\n",
    "print(\"Training classifiers …\")\n",
    "\n",
    "print(\"  Training KNN...\")\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "print(\"  Training SVM...\")\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "print(\"  Training Random Forest...\")\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "print(\"All classifiers trained successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Predictions\n",
    "print(\"Making predictions...\")\n",
    "\n",
    "knn_pred = knn.predict(X_test)\n",
    "svm_pred = svm.predict(X_test)\n",
    "rf_pred  = rf.predict(X_test)\n",
    "\n",
    "print(\"Predictions completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Individual Classifier Results\n",
    "print(\"Individual Classifier Accuracies:\")\n",
    "knn_acc = accuracy_score(y_test, knn_pred)\n",
    "svm_acc = accuracy_score(y_test, svm_pred)\n",
    "rf_acc = accuracy_score(y_test, rf_pred)\n",
    "\n",
    "print(f\"  KNN: {knn_acc:.4f}\")\n",
    "print(f\"  SVM: {svm_acc:.4f}\")\n",
    "print(f\"  RF : {rf_acc:.4f}\")\n",
    "\n",
    "# Display individual classification reports\n",
    "target_names = [id2label[i] for i in range(num_classes)]\n",
    "\n",
    "print(\"\\n=== KNN Classification Report ===\")\n",
    "print(classification_report(y_test, knn_pred, target_names=target_names))\n",
    "\n",
    "print(\"\\n=== SVM Classification Report ===\")\n",
    "print(classification_report(y_test, svm_pred, target_names=target_names))\n",
    "\n",
    "print(\"\\n=== Random Forest Classification Report ===\")\n",
    "print(classification_report(y_test, rf_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble Fusion (Majority Voting)\n",
    "preds = np.stack([knn_pred, svm_pred, rf_pred], axis=0)\n",
    "ens = mode(preds, axis=0, keepdims=False).mode\n",
    "ens_acc = accuracy_score(y_test, ens)\n",
    "\n",
    "print(f\"Ensemble Accuracy (Majority Voting): {ens_acc:.4f}\")\n",
    "print(f\"\\nImprovement over best individual: {ens_acc - max(knn_acc, svm_acc, rf_acc):.4f}\")\n",
    "\n",
    "print(\"\\n=== Ensemble Classification Report ===\")\n",
    "print(classification_report(y_test, ens, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary Results\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL RESULTS SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total samples processed: {len(y_full)}\")\n",
    "print(f\"Features selected by GA: {len(sel_idx)} / {n_features} ({len(sel_idx)/n_features:.1%})\")\n",
    "print(f\"Test set size: {len(y_test)}\")\n",
    "print(\"\\nClassifier Accuracies:\")\n",
    "print(f\"  KNN:              {knn_acc:.4f}\")\n",
    "print(f\"  SVM:              {svm_acc:.4f}\")\n",
    "print(f\"  Random Forest:    {rf_acc:.4f}\")\n",
    "print(f\"  Ensemble (Fusion): {ens_acc:.4f} ← BEST\")\n",
    "print(\"\\nClass Labels:\")\n",
    "for i, label in id2label.items():\n",
    "    print(f\"  {i}: {label}\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}